// =============================================================================
// DO NOT EDIT - This file is automatically generated by gremlin.zig
// =============================================================================
const std = @import("std");
const gremlin = @import("gremlin");
// structs
const AllocPagesIommuEndFtraceEventWire = struct {
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 1;
    const ORDER_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const AllocPagesIommuEndFtraceEvent = struct {
    // fields
    gfp_flags: u32 = 0,
    order: u32 = 0,
    pub fn calcProtobufSize(self: *const AllocPagesIommuEndFtraceEvent) usize {
        var res: usize = 0;
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesIommuEndFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.order != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesIommuEndFtraceEventWire.ORDER_WIRE) + gremlin.sizes.sizeU32(self.order);
        }
        return res;
    }
    pub fn encode(self: *const AllocPagesIommuEndFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const AllocPagesIommuEndFtraceEvent, target: *gremlin.Writer) void {
        if (self.gfp_flags != 0) {
            target.appendUint32(AllocPagesIommuEndFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.order != 0) {
            target.appendUint32(AllocPagesIommuEndFtraceEventWire.ORDER_WIRE, self.order);
        }
    }
};
pub const AllocPagesIommuEndFtraceEventReader = struct {
    buf: gremlin.Reader,
    _gfp_flags: u32 = 0,
    _order: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!AllocPagesIommuEndFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = AllocPagesIommuEndFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                AllocPagesIommuEndFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                AllocPagesIommuEndFtraceEventWire.ORDER_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._order = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getGfpFlags(self: *const AllocPagesIommuEndFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getOrder(self: *const AllocPagesIommuEndFtraceEventReader) u32 {
        return self._order;
    }
};
const AllocPagesIommuFailFtraceEventWire = struct {
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 1;
    const ORDER_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const AllocPagesIommuFailFtraceEvent = struct {
    // fields
    gfp_flags: u32 = 0,
    order: u32 = 0,
    pub fn calcProtobufSize(self: *const AllocPagesIommuFailFtraceEvent) usize {
        var res: usize = 0;
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesIommuFailFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.order != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesIommuFailFtraceEventWire.ORDER_WIRE) + gremlin.sizes.sizeU32(self.order);
        }
        return res;
    }
    pub fn encode(self: *const AllocPagesIommuFailFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const AllocPagesIommuFailFtraceEvent, target: *gremlin.Writer) void {
        if (self.gfp_flags != 0) {
            target.appendUint32(AllocPagesIommuFailFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.order != 0) {
            target.appendUint32(AllocPagesIommuFailFtraceEventWire.ORDER_WIRE, self.order);
        }
    }
};
pub const AllocPagesIommuFailFtraceEventReader = struct {
    buf: gremlin.Reader,
    _gfp_flags: u32 = 0,
    _order: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!AllocPagesIommuFailFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = AllocPagesIommuFailFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                AllocPagesIommuFailFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                AllocPagesIommuFailFtraceEventWire.ORDER_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._order = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getGfpFlags(self: *const AllocPagesIommuFailFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getOrder(self: *const AllocPagesIommuFailFtraceEventReader) u32 {
        return self._order;
    }
};
const AllocPagesIommuStartFtraceEventWire = struct {
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 1;
    const ORDER_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const AllocPagesIommuStartFtraceEvent = struct {
    // fields
    gfp_flags: u32 = 0,
    order: u32 = 0,
    pub fn calcProtobufSize(self: *const AllocPagesIommuStartFtraceEvent) usize {
        var res: usize = 0;
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesIommuStartFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.order != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesIommuStartFtraceEventWire.ORDER_WIRE) + gremlin.sizes.sizeU32(self.order);
        }
        return res;
    }
    pub fn encode(self: *const AllocPagesIommuStartFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const AllocPagesIommuStartFtraceEvent, target: *gremlin.Writer) void {
        if (self.gfp_flags != 0) {
            target.appendUint32(AllocPagesIommuStartFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.order != 0) {
            target.appendUint32(AllocPagesIommuStartFtraceEventWire.ORDER_WIRE, self.order);
        }
    }
};
pub const AllocPagesIommuStartFtraceEventReader = struct {
    buf: gremlin.Reader,
    _gfp_flags: u32 = 0,
    _order: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!AllocPagesIommuStartFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = AllocPagesIommuStartFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                AllocPagesIommuStartFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                AllocPagesIommuStartFtraceEventWire.ORDER_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._order = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getGfpFlags(self: *const AllocPagesIommuStartFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getOrder(self: *const AllocPagesIommuStartFtraceEventReader) u32 {
        return self._order;
    }
};
const AllocPagesSysEndFtraceEventWire = struct {
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 1;
    const ORDER_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const AllocPagesSysEndFtraceEvent = struct {
    // fields
    gfp_flags: u32 = 0,
    order: u32 = 0,
    pub fn calcProtobufSize(self: *const AllocPagesSysEndFtraceEvent) usize {
        var res: usize = 0;
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesSysEndFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.order != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesSysEndFtraceEventWire.ORDER_WIRE) + gremlin.sizes.sizeU32(self.order);
        }
        return res;
    }
    pub fn encode(self: *const AllocPagesSysEndFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const AllocPagesSysEndFtraceEvent, target: *gremlin.Writer) void {
        if (self.gfp_flags != 0) {
            target.appendUint32(AllocPagesSysEndFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.order != 0) {
            target.appendUint32(AllocPagesSysEndFtraceEventWire.ORDER_WIRE, self.order);
        }
    }
};
pub const AllocPagesSysEndFtraceEventReader = struct {
    buf: gremlin.Reader,
    _gfp_flags: u32 = 0,
    _order: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!AllocPagesSysEndFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = AllocPagesSysEndFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                AllocPagesSysEndFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                AllocPagesSysEndFtraceEventWire.ORDER_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._order = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getGfpFlags(self: *const AllocPagesSysEndFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getOrder(self: *const AllocPagesSysEndFtraceEventReader) u32 {
        return self._order;
    }
};
const AllocPagesSysFailFtraceEventWire = struct {
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 1;
    const ORDER_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const AllocPagesSysFailFtraceEvent = struct {
    // fields
    gfp_flags: u32 = 0,
    order: u32 = 0,
    pub fn calcProtobufSize(self: *const AllocPagesSysFailFtraceEvent) usize {
        var res: usize = 0;
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesSysFailFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.order != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesSysFailFtraceEventWire.ORDER_WIRE) + gremlin.sizes.sizeU32(self.order);
        }
        return res;
    }
    pub fn encode(self: *const AllocPagesSysFailFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const AllocPagesSysFailFtraceEvent, target: *gremlin.Writer) void {
        if (self.gfp_flags != 0) {
            target.appendUint32(AllocPagesSysFailFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.order != 0) {
            target.appendUint32(AllocPagesSysFailFtraceEventWire.ORDER_WIRE, self.order);
        }
    }
};
pub const AllocPagesSysFailFtraceEventReader = struct {
    buf: gremlin.Reader,
    _gfp_flags: u32 = 0,
    _order: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!AllocPagesSysFailFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = AllocPagesSysFailFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                AllocPagesSysFailFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                AllocPagesSysFailFtraceEventWire.ORDER_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._order = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getGfpFlags(self: *const AllocPagesSysFailFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getOrder(self: *const AllocPagesSysFailFtraceEventReader) u32 {
        return self._order;
    }
};
const AllocPagesSysStartFtraceEventWire = struct {
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 1;
    const ORDER_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const AllocPagesSysStartFtraceEvent = struct {
    // fields
    gfp_flags: u32 = 0,
    order: u32 = 0,
    pub fn calcProtobufSize(self: *const AllocPagesSysStartFtraceEvent) usize {
        var res: usize = 0;
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesSysStartFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.order != 0) {
            res += gremlin.sizes.sizeWireNumber(AllocPagesSysStartFtraceEventWire.ORDER_WIRE) + gremlin.sizes.sizeU32(self.order);
        }
        return res;
    }
    pub fn encode(self: *const AllocPagesSysStartFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const AllocPagesSysStartFtraceEvent, target: *gremlin.Writer) void {
        if (self.gfp_flags != 0) {
            target.appendUint32(AllocPagesSysStartFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.order != 0) {
            target.appendUint32(AllocPagesSysStartFtraceEventWire.ORDER_WIRE, self.order);
        }
    }
};
pub const AllocPagesSysStartFtraceEventReader = struct {
    buf: gremlin.Reader,
    _gfp_flags: u32 = 0,
    _order: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!AllocPagesSysStartFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = AllocPagesSysStartFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                AllocPagesSysStartFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                AllocPagesSysStartFtraceEventWire.ORDER_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._order = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getGfpFlags(self: *const AllocPagesSysStartFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getOrder(self: *const AllocPagesSysStartFtraceEventReader) u32 {
        return self._order;
    }
};
const DmaAllocContiguousRetryFtraceEventWire = struct {
    const TRIES_WIRE: gremlin.ProtoWireNumber = 1;
};
pub const DmaAllocContiguousRetryFtraceEvent = struct {
    // fields
    tries: i32 = 0,
    pub fn calcProtobufSize(self: *const DmaAllocContiguousRetryFtraceEvent) usize {
        var res: usize = 0;
        if (self.tries != 0) {
            res += gremlin.sizes.sizeWireNumber(DmaAllocContiguousRetryFtraceEventWire.TRIES_WIRE) + gremlin.sizes.sizeI32(self.tries);
        }
        return res;
    }
    pub fn encode(self: *const DmaAllocContiguousRetryFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const DmaAllocContiguousRetryFtraceEvent, target: *gremlin.Writer) void {
        if (self.tries != 0) {
            target.appendInt32(DmaAllocContiguousRetryFtraceEventWire.TRIES_WIRE, self.tries);
        }
    }
};
pub const DmaAllocContiguousRetryFtraceEventReader = struct {
    buf: gremlin.Reader,
    _tries: i32 = 0,
    pub fn init(src: []const u8) gremlin.Error!DmaAllocContiguousRetryFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = DmaAllocContiguousRetryFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                DmaAllocContiguousRetryFtraceEventWire.TRIES_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._tries = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getTries(self: *const DmaAllocContiguousRetryFtraceEventReader) i32 {
        return self._tries;
    }
};
const IommuMapRangeFtraceEventWire = struct {
    const CHUNK_SIZE_WIRE: gremlin.ProtoWireNumber = 1;
    const LEN_WIRE: gremlin.ProtoWireNumber = 2;
    const PA_WIRE: gremlin.ProtoWireNumber = 3;
    const VA_WIRE: gremlin.ProtoWireNumber = 4;
};
pub const IommuMapRangeFtraceEvent = struct {
    // fields
    chunk_size: u64 = 0,
    len: u64 = 0,
    pa: u64 = 0,
    va: u64 = 0,
    pub fn calcProtobufSize(self: *const IommuMapRangeFtraceEvent) usize {
        var res: usize = 0;
        if (self.chunk_size != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuMapRangeFtraceEventWire.CHUNK_SIZE_WIRE) + gremlin.sizes.sizeU64(self.chunk_size);
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuMapRangeFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.pa != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuMapRangeFtraceEventWire.PA_WIRE) + gremlin.sizes.sizeU64(self.pa);
        }
        if (self.va != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuMapRangeFtraceEventWire.VA_WIRE) + gremlin.sizes.sizeU64(self.va);
        }
        return res;
    }
    pub fn encode(self: *const IommuMapRangeFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IommuMapRangeFtraceEvent, target: *gremlin.Writer) void {
        if (self.chunk_size != 0) {
            target.appendUint64(IommuMapRangeFtraceEventWire.CHUNK_SIZE_WIRE, self.chunk_size);
        }
        if (self.len != 0) {
            target.appendUint64(IommuMapRangeFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.pa != 0) {
            target.appendUint64(IommuMapRangeFtraceEventWire.PA_WIRE, self.pa);
        }
        if (self.va != 0) {
            target.appendUint64(IommuMapRangeFtraceEventWire.VA_WIRE, self.va);
        }
    }
};
pub const IommuMapRangeFtraceEventReader = struct {
    buf: gremlin.Reader,
    _chunk_size: u64 = 0,
    _len: u64 = 0,
    _pa: u64 = 0,
    _va: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IommuMapRangeFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IommuMapRangeFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IommuMapRangeFtraceEventWire.CHUNK_SIZE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._chunk_size = result.value;
                },
                IommuMapRangeFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IommuMapRangeFtraceEventWire.PA_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._pa = result.value;
                },
                IommuMapRangeFtraceEventWire.VA_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._va = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getChunkSize(self: *const IommuMapRangeFtraceEventReader) u64 {
        return self._chunk_size;
    }
    pub inline fn getLen(self: *const IommuMapRangeFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getPa(self: *const IommuMapRangeFtraceEventReader) u64 {
        return self._pa;
    }
    pub inline fn getVa(self: *const IommuMapRangeFtraceEventReader) u64 {
        return self._va;
    }
};
const IommuSecPtblMapRangeEndFtraceEventWire = struct {
    const LEN_WIRE: gremlin.ProtoWireNumber = 1;
    const NUM_WIRE: gremlin.ProtoWireNumber = 2;
    const PA_WIRE: gremlin.ProtoWireNumber = 3;
    const SEC_ID_WIRE: gremlin.ProtoWireNumber = 4;
    const VA_WIRE: gremlin.ProtoWireNumber = 5;
};
pub const IommuSecPtblMapRangeEndFtraceEvent = struct {
    // fields
    len: u64 = 0,
    num: i32 = 0,
    pa: u32 = 0,
    sec_id: i32 = 0,
    va: u64 = 0,
    pub fn calcProtobufSize(self: *const IommuSecPtblMapRangeEndFtraceEvent) usize {
        var res: usize = 0;
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuSecPtblMapRangeEndFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.num != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuSecPtblMapRangeEndFtraceEventWire.NUM_WIRE) + gremlin.sizes.sizeI32(self.num);
        }
        if (self.pa != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuSecPtblMapRangeEndFtraceEventWire.PA_WIRE) + gremlin.sizes.sizeU32(self.pa);
        }
        if (self.sec_id != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuSecPtblMapRangeEndFtraceEventWire.SEC_ID_WIRE) + gremlin.sizes.sizeI32(self.sec_id);
        }
        if (self.va != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuSecPtblMapRangeEndFtraceEventWire.VA_WIRE) + gremlin.sizes.sizeU64(self.va);
        }
        return res;
    }
    pub fn encode(self: *const IommuSecPtblMapRangeEndFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IommuSecPtblMapRangeEndFtraceEvent, target: *gremlin.Writer) void {
        if (self.len != 0) {
            target.appendUint64(IommuSecPtblMapRangeEndFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.num != 0) {
            target.appendInt32(IommuSecPtblMapRangeEndFtraceEventWire.NUM_WIRE, self.num);
        }
        if (self.pa != 0) {
            target.appendUint32(IommuSecPtblMapRangeEndFtraceEventWire.PA_WIRE, self.pa);
        }
        if (self.sec_id != 0) {
            target.appendInt32(IommuSecPtblMapRangeEndFtraceEventWire.SEC_ID_WIRE, self.sec_id);
        }
        if (self.va != 0) {
            target.appendUint64(IommuSecPtblMapRangeEndFtraceEventWire.VA_WIRE, self.va);
        }
    }
};
pub const IommuSecPtblMapRangeEndFtraceEventReader = struct {
    buf: gremlin.Reader,
    _len: u64 = 0,
    _num: i32 = 0,
    _pa: u32 = 0,
    _sec_id: i32 = 0,
    _va: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IommuSecPtblMapRangeEndFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IommuSecPtblMapRangeEndFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IommuSecPtblMapRangeEndFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IommuSecPtblMapRangeEndFtraceEventWire.NUM_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._num = result.value;
                },
                IommuSecPtblMapRangeEndFtraceEventWire.PA_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._pa = result.value;
                },
                IommuSecPtblMapRangeEndFtraceEventWire.SEC_ID_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._sec_id = result.value;
                },
                IommuSecPtblMapRangeEndFtraceEventWire.VA_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._va = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getLen(self: *const IommuSecPtblMapRangeEndFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getNum(self: *const IommuSecPtblMapRangeEndFtraceEventReader) i32 {
        return self._num;
    }
    pub inline fn getPa(self: *const IommuSecPtblMapRangeEndFtraceEventReader) u32 {
        return self._pa;
    }
    pub inline fn getSecId(self: *const IommuSecPtblMapRangeEndFtraceEventReader) i32 {
        return self._sec_id;
    }
    pub inline fn getVa(self: *const IommuSecPtblMapRangeEndFtraceEventReader) u64 {
        return self._va;
    }
};
const IommuSecPtblMapRangeStartFtraceEventWire = struct {
    const LEN_WIRE: gremlin.ProtoWireNumber = 1;
    const NUM_WIRE: gremlin.ProtoWireNumber = 2;
    const PA_WIRE: gremlin.ProtoWireNumber = 3;
    const SEC_ID_WIRE: gremlin.ProtoWireNumber = 4;
    const VA_WIRE: gremlin.ProtoWireNumber = 5;
};
pub const IommuSecPtblMapRangeStartFtraceEvent = struct {
    // fields
    len: u64 = 0,
    num: i32 = 0,
    pa: u32 = 0,
    sec_id: i32 = 0,
    va: u64 = 0,
    pub fn calcProtobufSize(self: *const IommuSecPtblMapRangeStartFtraceEvent) usize {
        var res: usize = 0;
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuSecPtblMapRangeStartFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.num != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuSecPtblMapRangeStartFtraceEventWire.NUM_WIRE) + gremlin.sizes.sizeI32(self.num);
        }
        if (self.pa != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuSecPtblMapRangeStartFtraceEventWire.PA_WIRE) + gremlin.sizes.sizeU32(self.pa);
        }
        if (self.sec_id != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuSecPtblMapRangeStartFtraceEventWire.SEC_ID_WIRE) + gremlin.sizes.sizeI32(self.sec_id);
        }
        if (self.va != 0) {
            res += gremlin.sizes.sizeWireNumber(IommuSecPtblMapRangeStartFtraceEventWire.VA_WIRE) + gremlin.sizes.sizeU64(self.va);
        }
        return res;
    }
    pub fn encode(self: *const IommuSecPtblMapRangeStartFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IommuSecPtblMapRangeStartFtraceEvent, target: *gremlin.Writer) void {
        if (self.len != 0) {
            target.appendUint64(IommuSecPtblMapRangeStartFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.num != 0) {
            target.appendInt32(IommuSecPtblMapRangeStartFtraceEventWire.NUM_WIRE, self.num);
        }
        if (self.pa != 0) {
            target.appendUint32(IommuSecPtblMapRangeStartFtraceEventWire.PA_WIRE, self.pa);
        }
        if (self.sec_id != 0) {
            target.appendInt32(IommuSecPtblMapRangeStartFtraceEventWire.SEC_ID_WIRE, self.sec_id);
        }
        if (self.va != 0) {
            target.appendUint64(IommuSecPtblMapRangeStartFtraceEventWire.VA_WIRE, self.va);
        }
    }
};
pub const IommuSecPtblMapRangeStartFtraceEventReader = struct {
    buf: gremlin.Reader,
    _len: u64 = 0,
    _num: i32 = 0,
    _pa: u32 = 0,
    _sec_id: i32 = 0,
    _va: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IommuSecPtblMapRangeStartFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IommuSecPtblMapRangeStartFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IommuSecPtblMapRangeStartFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IommuSecPtblMapRangeStartFtraceEventWire.NUM_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._num = result.value;
                },
                IommuSecPtblMapRangeStartFtraceEventWire.PA_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._pa = result.value;
                },
                IommuSecPtblMapRangeStartFtraceEventWire.SEC_ID_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._sec_id = result.value;
                },
                IommuSecPtblMapRangeStartFtraceEventWire.VA_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._va = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getLen(self: *const IommuSecPtblMapRangeStartFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getNum(self: *const IommuSecPtblMapRangeStartFtraceEventReader) i32 {
        return self._num;
    }
    pub inline fn getPa(self: *const IommuSecPtblMapRangeStartFtraceEventReader) u32 {
        return self._pa;
    }
    pub inline fn getSecId(self: *const IommuSecPtblMapRangeStartFtraceEventReader) i32 {
        return self._sec_id;
    }
    pub inline fn getVa(self: *const IommuSecPtblMapRangeStartFtraceEventReader) u64 {
        return self._va;
    }
};
const IonAllocBufferEndFtraceEventWire = struct {
    const CLIENT_NAME_WIRE: gremlin.ProtoWireNumber = 1;
    const FLAGS_WIRE: gremlin.ProtoWireNumber = 2;
    const HEAP_NAME_WIRE: gremlin.ProtoWireNumber = 3;
    const LEN_WIRE: gremlin.ProtoWireNumber = 4;
    const MASK_WIRE: gremlin.ProtoWireNumber = 5;
};
pub const IonAllocBufferEndFtraceEvent = struct {
    // fields
    client_name: ?[]const u8 = null,
    flags: u32 = 0,
    heap_name: ?[]const u8 = null,
    len: u64 = 0,
    mask: u32 = 0,
    pub fn calcProtobufSize(self: *const IonAllocBufferEndFtraceEvent) usize {
        var res: usize = 0;
        if (self.client_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonAllocBufferEndFtraceEventWire.CLIENT_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.flags != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferEndFtraceEventWire.FLAGS_WIRE) + gremlin.sizes.sizeU32(self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonAllocBufferEndFtraceEventWire.HEAP_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferEndFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.mask != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferEndFtraceEventWire.MASK_WIRE) + gremlin.sizes.sizeU32(self.mask);
        }
        return res;
    }
    pub fn encode(self: *const IonAllocBufferEndFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonAllocBufferEndFtraceEvent, target: *gremlin.Writer) void {
        if (self.client_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonAllocBufferEndFtraceEventWire.CLIENT_NAME_WIRE, v);
            }
        }
        if (self.flags != 0) {
            target.appendUint32(IonAllocBufferEndFtraceEventWire.FLAGS_WIRE, self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonAllocBufferEndFtraceEventWire.HEAP_NAME_WIRE, v);
            }
        }
        if (self.len != 0) {
            target.appendUint64(IonAllocBufferEndFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.mask != 0) {
            target.appendUint32(IonAllocBufferEndFtraceEventWire.MASK_WIRE, self.mask);
        }
    }
};
pub const IonAllocBufferEndFtraceEventReader = struct {
    buf: gremlin.Reader,
    _client_name: ?[]const u8 = null,
    _flags: u32 = 0,
    _heap_name: ?[]const u8 = null,
    _len: u64 = 0,
    _mask: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonAllocBufferEndFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonAllocBufferEndFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonAllocBufferEndFtraceEventWire.CLIENT_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._client_name = result.value;
                },
                IonAllocBufferEndFtraceEventWire.FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._flags = result.value;
                },
                IonAllocBufferEndFtraceEventWire.HEAP_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._heap_name = result.value;
                },
                IonAllocBufferEndFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IonAllocBufferEndFtraceEventWire.MASK_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._mask = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getClientName(self: *const IonAllocBufferEndFtraceEventReader) []const u8 {
        return self._client_name orelse &[_]u8{};
    }
    pub inline fn getFlags(self: *const IonAllocBufferEndFtraceEventReader) u32 {
        return self._flags;
    }
    pub inline fn getHeapName(self: *const IonAllocBufferEndFtraceEventReader) []const u8 {
        return self._heap_name orelse &[_]u8{};
    }
    pub inline fn getLen(self: *const IonAllocBufferEndFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getMask(self: *const IonAllocBufferEndFtraceEventReader) u32 {
        return self._mask;
    }
};
const IonAllocBufferFailFtraceEventWire = struct {
    const CLIENT_NAME_WIRE: gremlin.ProtoWireNumber = 1;
    const ERROR_WIRE: gremlin.ProtoWireNumber = 2;
    const FLAGS_WIRE: gremlin.ProtoWireNumber = 3;
    const HEAP_NAME_WIRE: gremlin.ProtoWireNumber = 4;
    const LEN_WIRE: gremlin.ProtoWireNumber = 5;
    const MASK_WIRE: gremlin.ProtoWireNumber = 6;
};
pub const IonAllocBufferFailFtraceEvent = struct {
    // fields
    client_name: ?[]const u8 = null,
    error_: i64 = 0,
    flags: u32 = 0,
    heap_name: ?[]const u8 = null,
    len: u64 = 0,
    mask: u32 = 0,
    pub fn calcProtobufSize(self: *const IonAllocBufferFailFtraceEvent) usize {
        var res: usize = 0;
        if (self.client_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonAllocBufferFailFtraceEventWire.CLIENT_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.error_ != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferFailFtraceEventWire.ERROR_WIRE) + gremlin.sizes.sizeI64(self.error_);
        }
        if (self.flags != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferFailFtraceEventWire.FLAGS_WIRE) + gremlin.sizes.sizeU32(self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonAllocBufferFailFtraceEventWire.HEAP_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferFailFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.mask != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferFailFtraceEventWire.MASK_WIRE) + gremlin.sizes.sizeU32(self.mask);
        }
        return res;
    }
    pub fn encode(self: *const IonAllocBufferFailFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonAllocBufferFailFtraceEvent, target: *gremlin.Writer) void {
        if (self.client_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonAllocBufferFailFtraceEventWire.CLIENT_NAME_WIRE, v);
            }
        }
        if (self.error_ != 0) {
            target.appendInt64(IonAllocBufferFailFtraceEventWire.ERROR_WIRE, self.error_);
        }
        if (self.flags != 0) {
            target.appendUint32(IonAllocBufferFailFtraceEventWire.FLAGS_WIRE, self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonAllocBufferFailFtraceEventWire.HEAP_NAME_WIRE, v);
            }
        }
        if (self.len != 0) {
            target.appendUint64(IonAllocBufferFailFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.mask != 0) {
            target.appendUint32(IonAllocBufferFailFtraceEventWire.MASK_WIRE, self.mask);
        }
    }
};
pub const IonAllocBufferFailFtraceEventReader = struct {
    buf: gremlin.Reader,
    _client_name: ?[]const u8 = null,
    _error_: i64 = 0,
    _flags: u32 = 0,
    _heap_name: ?[]const u8 = null,
    _len: u64 = 0,
    _mask: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonAllocBufferFailFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonAllocBufferFailFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonAllocBufferFailFtraceEventWire.CLIENT_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._client_name = result.value;
                },
                IonAllocBufferFailFtraceEventWire.ERROR_WIRE => {
                    const result = try buf.readInt64(offset);
                    offset += result.size;
                    res._error_ = result.value;
                },
                IonAllocBufferFailFtraceEventWire.FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._flags = result.value;
                },
                IonAllocBufferFailFtraceEventWire.HEAP_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._heap_name = result.value;
                },
                IonAllocBufferFailFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IonAllocBufferFailFtraceEventWire.MASK_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._mask = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getClientName(self: *const IonAllocBufferFailFtraceEventReader) []const u8 {
        return self._client_name orelse &[_]u8{};
    }
    pub inline fn getError(self: *const IonAllocBufferFailFtraceEventReader) i64 {
        return self._error_;
    }
    pub inline fn getFlags(self: *const IonAllocBufferFailFtraceEventReader) u32 {
        return self._flags;
    }
    pub inline fn getHeapName(self: *const IonAllocBufferFailFtraceEventReader) []const u8 {
        return self._heap_name orelse &[_]u8{};
    }
    pub inline fn getLen(self: *const IonAllocBufferFailFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getMask(self: *const IonAllocBufferFailFtraceEventReader) u32 {
        return self._mask;
    }
};
const IonAllocBufferFallbackFtraceEventWire = struct {
    const CLIENT_NAME_WIRE: gremlin.ProtoWireNumber = 1;
    const ERROR_WIRE: gremlin.ProtoWireNumber = 2;
    const FLAGS_WIRE: gremlin.ProtoWireNumber = 3;
    const HEAP_NAME_WIRE: gremlin.ProtoWireNumber = 4;
    const LEN_WIRE: gremlin.ProtoWireNumber = 5;
    const MASK_WIRE: gremlin.ProtoWireNumber = 6;
};
pub const IonAllocBufferFallbackFtraceEvent = struct {
    // fields
    client_name: ?[]const u8 = null,
    error_: i64 = 0,
    flags: u32 = 0,
    heap_name: ?[]const u8 = null,
    len: u64 = 0,
    mask: u32 = 0,
    pub fn calcProtobufSize(self: *const IonAllocBufferFallbackFtraceEvent) usize {
        var res: usize = 0;
        if (self.client_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonAllocBufferFallbackFtraceEventWire.CLIENT_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.error_ != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferFallbackFtraceEventWire.ERROR_WIRE) + gremlin.sizes.sizeI64(self.error_);
        }
        if (self.flags != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferFallbackFtraceEventWire.FLAGS_WIRE) + gremlin.sizes.sizeU32(self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonAllocBufferFallbackFtraceEventWire.HEAP_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferFallbackFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.mask != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferFallbackFtraceEventWire.MASK_WIRE) + gremlin.sizes.sizeU32(self.mask);
        }
        return res;
    }
    pub fn encode(self: *const IonAllocBufferFallbackFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonAllocBufferFallbackFtraceEvent, target: *gremlin.Writer) void {
        if (self.client_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonAllocBufferFallbackFtraceEventWire.CLIENT_NAME_WIRE, v);
            }
        }
        if (self.error_ != 0) {
            target.appendInt64(IonAllocBufferFallbackFtraceEventWire.ERROR_WIRE, self.error_);
        }
        if (self.flags != 0) {
            target.appendUint32(IonAllocBufferFallbackFtraceEventWire.FLAGS_WIRE, self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonAllocBufferFallbackFtraceEventWire.HEAP_NAME_WIRE, v);
            }
        }
        if (self.len != 0) {
            target.appendUint64(IonAllocBufferFallbackFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.mask != 0) {
            target.appendUint32(IonAllocBufferFallbackFtraceEventWire.MASK_WIRE, self.mask);
        }
    }
};
pub const IonAllocBufferFallbackFtraceEventReader = struct {
    buf: gremlin.Reader,
    _client_name: ?[]const u8 = null,
    _error_: i64 = 0,
    _flags: u32 = 0,
    _heap_name: ?[]const u8 = null,
    _len: u64 = 0,
    _mask: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonAllocBufferFallbackFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonAllocBufferFallbackFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonAllocBufferFallbackFtraceEventWire.CLIENT_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._client_name = result.value;
                },
                IonAllocBufferFallbackFtraceEventWire.ERROR_WIRE => {
                    const result = try buf.readInt64(offset);
                    offset += result.size;
                    res._error_ = result.value;
                },
                IonAllocBufferFallbackFtraceEventWire.FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._flags = result.value;
                },
                IonAllocBufferFallbackFtraceEventWire.HEAP_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._heap_name = result.value;
                },
                IonAllocBufferFallbackFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IonAllocBufferFallbackFtraceEventWire.MASK_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._mask = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getClientName(self: *const IonAllocBufferFallbackFtraceEventReader) []const u8 {
        return self._client_name orelse &[_]u8{};
    }
    pub inline fn getError(self: *const IonAllocBufferFallbackFtraceEventReader) i64 {
        return self._error_;
    }
    pub inline fn getFlags(self: *const IonAllocBufferFallbackFtraceEventReader) u32 {
        return self._flags;
    }
    pub inline fn getHeapName(self: *const IonAllocBufferFallbackFtraceEventReader) []const u8 {
        return self._heap_name orelse &[_]u8{};
    }
    pub inline fn getLen(self: *const IonAllocBufferFallbackFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getMask(self: *const IonAllocBufferFallbackFtraceEventReader) u32 {
        return self._mask;
    }
};
const IonAllocBufferStartFtraceEventWire = struct {
    const CLIENT_NAME_WIRE: gremlin.ProtoWireNumber = 1;
    const FLAGS_WIRE: gremlin.ProtoWireNumber = 2;
    const HEAP_NAME_WIRE: gremlin.ProtoWireNumber = 3;
    const LEN_WIRE: gremlin.ProtoWireNumber = 4;
    const MASK_WIRE: gremlin.ProtoWireNumber = 5;
};
pub const IonAllocBufferStartFtraceEvent = struct {
    // fields
    client_name: ?[]const u8 = null,
    flags: u32 = 0,
    heap_name: ?[]const u8 = null,
    len: u64 = 0,
    mask: u32 = 0,
    pub fn calcProtobufSize(self: *const IonAllocBufferStartFtraceEvent) usize {
        var res: usize = 0;
        if (self.client_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonAllocBufferStartFtraceEventWire.CLIENT_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.flags != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferStartFtraceEventWire.FLAGS_WIRE) + gremlin.sizes.sizeU32(self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonAllocBufferStartFtraceEventWire.HEAP_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferStartFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.mask != 0) {
            res += gremlin.sizes.sizeWireNumber(IonAllocBufferStartFtraceEventWire.MASK_WIRE) + gremlin.sizes.sizeU32(self.mask);
        }
        return res;
    }
    pub fn encode(self: *const IonAllocBufferStartFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonAllocBufferStartFtraceEvent, target: *gremlin.Writer) void {
        if (self.client_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonAllocBufferStartFtraceEventWire.CLIENT_NAME_WIRE, v);
            }
        }
        if (self.flags != 0) {
            target.appendUint32(IonAllocBufferStartFtraceEventWire.FLAGS_WIRE, self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonAllocBufferStartFtraceEventWire.HEAP_NAME_WIRE, v);
            }
        }
        if (self.len != 0) {
            target.appendUint64(IonAllocBufferStartFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.mask != 0) {
            target.appendUint32(IonAllocBufferStartFtraceEventWire.MASK_WIRE, self.mask);
        }
    }
};
pub const IonAllocBufferStartFtraceEventReader = struct {
    buf: gremlin.Reader,
    _client_name: ?[]const u8 = null,
    _flags: u32 = 0,
    _heap_name: ?[]const u8 = null,
    _len: u64 = 0,
    _mask: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonAllocBufferStartFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonAllocBufferStartFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonAllocBufferStartFtraceEventWire.CLIENT_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._client_name = result.value;
                },
                IonAllocBufferStartFtraceEventWire.FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._flags = result.value;
                },
                IonAllocBufferStartFtraceEventWire.HEAP_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._heap_name = result.value;
                },
                IonAllocBufferStartFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IonAllocBufferStartFtraceEventWire.MASK_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._mask = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getClientName(self: *const IonAllocBufferStartFtraceEventReader) []const u8 {
        return self._client_name orelse &[_]u8{};
    }
    pub inline fn getFlags(self: *const IonAllocBufferStartFtraceEventReader) u32 {
        return self._flags;
    }
    pub inline fn getHeapName(self: *const IonAllocBufferStartFtraceEventReader) []const u8 {
        return self._heap_name orelse &[_]u8{};
    }
    pub inline fn getLen(self: *const IonAllocBufferStartFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getMask(self: *const IonAllocBufferStartFtraceEventReader) u32 {
        return self._mask;
    }
};
const IonCpAllocRetryFtraceEventWire = struct {
    const TRIES_WIRE: gremlin.ProtoWireNumber = 1;
};
pub const IonCpAllocRetryFtraceEvent = struct {
    // fields
    tries: i32 = 0,
    pub fn calcProtobufSize(self: *const IonCpAllocRetryFtraceEvent) usize {
        var res: usize = 0;
        if (self.tries != 0) {
            res += gremlin.sizes.sizeWireNumber(IonCpAllocRetryFtraceEventWire.TRIES_WIRE) + gremlin.sizes.sizeI32(self.tries);
        }
        return res;
    }
    pub fn encode(self: *const IonCpAllocRetryFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonCpAllocRetryFtraceEvent, target: *gremlin.Writer) void {
        if (self.tries != 0) {
            target.appendInt32(IonCpAllocRetryFtraceEventWire.TRIES_WIRE, self.tries);
        }
    }
};
pub const IonCpAllocRetryFtraceEventReader = struct {
    buf: gremlin.Reader,
    _tries: i32 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonCpAllocRetryFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonCpAllocRetryFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonCpAllocRetryFtraceEventWire.TRIES_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._tries = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getTries(self: *const IonCpAllocRetryFtraceEventReader) i32 {
        return self._tries;
    }
};
const IonCpSecureBufferEndFtraceEventWire = struct {
    const ALIGN_WIRE: gremlin.ProtoWireNumber = 1;
    const FLAGS_WIRE: gremlin.ProtoWireNumber = 2;
    const HEAP_NAME_WIRE: gremlin.ProtoWireNumber = 3;
    const LEN_WIRE: gremlin.ProtoWireNumber = 4;
};
pub const IonCpSecureBufferEndFtraceEvent = struct {
    // fields
    align_: u64 = 0,
    flags: u64 = 0,
    heap_name: ?[]const u8 = null,
    len: u64 = 0,
    pub fn calcProtobufSize(self: *const IonCpSecureBufferEndFtraceEvent) usize {
        var res: usize = 0;
        if (self.align_ != 0) {
            res += gremlin.sizes.sizeWireNumber(IonCpSecureBufferEndFtraceEventWire.ALIGN_WIRE) + gremlin.sizes.sizeU64(self.align_);
        }
        if (self.flags != 0) {
            res += gremlin.sizes.sizeWireNumber(IonCpSecureBufferEndFtraceEventWire.FLAGS_WIRE) + gremlin.sizes.sizeU64(self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonCpSecureBufferEndFtraceEventWire.HEAP_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonCpSecureBufferEndFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        return res;
    }
    pub fn encode(self: *const IonCpSecureBufferEndFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonCpSecureBufferEndFtraceEvent, target: *gremlin.Writer) void {
        if (self.align_ != 0) {
            target.appendUint64(IonCpSecureBufferEndFtraceEventWire.ALIGN_WIRE, self.align_);
        }
        if (self.flags != 0) {
            target.appendUint64(IonCpSecureBufferEndFtraceEventWire.FLAGS_WIRE, self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonCpSecureBufferEndFtraceEventWire.HEAP_NAME_WIRE, v);
            }
        }
        if (self.len != 0) {
            target.appendUint64(IonCpSecureBufferEndFtraceEventWire.LEN_WIRE, self.len);
        }
    }
};
pub const IonCpSecureBufferEndFtraceEventReader = struct {
    buf: gremlin.Reader,
    _align_: u64 = 0,
    _flags: u64 = 0,
    _heap_name: ?[]const u8 = null,
    _len: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonCpSecureBufferEndFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonCpSecureBufferEndFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonCpSecureBufferEndFtraceEventWire.ALIGN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._align_ = result.value;
                },
                IonCpSecureBufferEndFtraceEventWire.FLAGS_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._flags = result.value;
                },
                IonCpSecureBufferEndFtraceEventWire.HEAP_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._heap_name = result.value;
                },
                IonCpSecureBufferEndFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getAlign(self: *const IonCpSecureBufferEndFtraceEventReader) u64 {
        return self._align_;
    }
    pub inline fn getFlags(self: *const IonCpSecureBufferEndFtraceEventReader) u64 {
        return self._flags;
    }
    pub inline fn getHeapName(self: *const IonCpSecureBufferEndFtraceEventReader) []const u8 {
        return self._heap_name orelse &[_]u8{};
    }
    pub inline fn getLen(self: *const IonCpSecureBufferEndFtraceEventReader) u64 {
        return self._len;
    }
};
const IonCpSecureBufferStartFtraceEventWire = struct {
    const ALIGN_WIRE: gremlin.ProtoWireNumber = 1;
    const FLAGS_WIRE: gremlin.ProtoWireNumber = 2;
    const HEAP_NAME_WIRE: gremlin.ProtoWireNumber = 3;
    const LEN_WIRE: gremlin.ProtoWireNumber = 4;
};
pub const IonCpSecureBufferStartFtraceEvent = struct {
    // fields
    align_: u64 = 0,
    flags: u64 = 0,
    heap_name: ?[]const u8 = null,
    len: u64 = 0,
    pub fn calcProtobufSize(self: *const IonCpSecureBufferStartFtraceEvent) usize {
        var res: usize = 0;
        if (self.align_ != 0) {
            res += gremlin.sizes.sizeWireNumber(IonCpSecureBufferStartFtraceEventWire.ALIGN_WIRE) + gremlin.sizes.sizeU64(self.align_);
        }
        if (self.flags != 0) {
            res += gremlin.sizes.sizeWireNumber(IonCpSecureBufferStartFtraceEventWire.FLAGS_WIRE) + gremlin.sizes.sizeU64(self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonCpSecureBufferStartFtraceEventWire.HEAP_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonCpSecureBufferStartFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        return res;
    }
    pub fn encode(self: *const IonCpSecureBufferStartFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonCpSecureBufferStartFtraceEvent, target: *gremlin.Writer) void {
        if (self.align_ != 0) {
            target.appendUint64(IonCpSecureBufferStartFtraceEventWire.ALIGN_WIRE, self.align_);
        }
        if (self.flags != 0) {
            target.appendUint64(IonCpSecureBufferStartFtraceEventWire.FLAGS_WIRE, self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonCpSecureBufferStartFtraceEventWire.HEAP_NAME_WIRE, v);
            }
        }
        if (self.len != 0) {
            target.appendUint64(IonCpSecureBufferStartFtraceEventWire.LEN_WIRE, self.len);
        }
    }
};
pub const IonCpSecureBufferStartFtraceEventReader = struct {
    buf: gremlin.Reader,
    _align_: u64 = 0,
    _flags: u64 = 0,
    _heap_name: ?[]const u8 = null,
    _len: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonCpSecureBufferStartFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonCpSecureBufferStartFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonCpSecureBufferStartFtraceEventWire.ALIGN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._align_ = result.value;
                },
                IonCpSecureBufferStartFtraceEventWire.FLAGS_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._flags = result.value;
                },
                IonCpSecureBufferStartFtraceEventWire.HEAP_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._heap_name = result.value;
                },
                IonCpSecureBufferStartFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getAlign(self: *const IonCpSecureBufferStartFtraceEventReader) u64 {
        return self._align_;
    }
    pub inline fn getFlags(self: *const IonCpSecureBufferStartFtraceEventReader) u64 {
        return self._flags;
    }
    pub inline fn getHeapName(self: *const IonCpSecureBufferStartFtraceEventReader) []const u8 {
        return self._heap_name orelse &[_]u8{};
    }
    pub inline fn getLen(self: *const IonCpSecureBufferStartFtraceEventReader) u64 {
        return self._len;
    }
};
const IonPrefetchingFtraceEventWire = struct {
    const LEN_WIRE: gremlin.ProtoWireNumber = 1;
};
pub const IonPrefetchingFtraceEvent = struct {
    // fields
    len: u64 = 0,
    pub fn calcProtobufSize(self: *const IonPrefetchingFtraceEvent) usize {
        var res: usize = 0;
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonPrefetchingFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        return res;
    }
    pub fn encode(self: *const IonPrefetchingFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonPrefetchingFtraceEvent, target: *gremlin.Writer) void {
        if (self.len != 0) {
            target.appendUint64(IonPrefetchingFtraceEventWire.LEN_WIRE, self.len);
        }
    }
};
pub const IonPrefetchingFtraceEventReader = struct {
    buf: gremlin.Reader,
    _len: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonPrefetchingFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonPrefetchingFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonPrefetchingFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getLen(self: *const IonPrefetchingFtraceEventReader) u64 {
        return self._len;
    }
};
const IonSecureCmaAddToPoolEndFtraceEventWire = struct {
    const IS_PREFETCH_WIRE: gremlin.ProtoWireNumber = 1;
    const LEN_WIRE: gremlin.ProtoWireNumber = 2;
    const POOL_TOTAL_WIRE: gremlin.ProtoWireNumber = 3;
};
pub const IonSecureCmaAddToPoolEndFtraceEvent = struct {
    // fields
    is_prefetch: u32 = 0,
    len: u64 = 0,
    pool_total: i32 = 0,
    pub fn calcProtobufSize(self: *const IonSecureCmaAddToPoolEndFtraceEvent) usize {
        var res: usize = 0;
        if (self.is_prefetch != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAddToPoolEndFtraceEventWire.IS_PREFETCH_WIRE) + gremlin.sizes.sizeU32(self.is_prefetch);
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAddToPoolEndFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.pool_total != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAddToPoolEndFtraceEventWire.POOL_TOTAL_WIRE) + gremlin.sizes.sizeI32(self.pool_total);
        }
        return res;
    }
    pub fn encode(self: *const IonSecureCmaAddToPoolEndFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonSecureCmaAddToPoolEndFtraceEvent, target: *gremlin.Writer) void {
        if (self.is_prefetch != 0) {
            target.appendUint32(IonSecureCmaAddToPoolEndFtraceEventWire.IS_PREFETCH_WIRE, self.is_prefetch);
        }
        if (self.len != 0) {
            target.appendUint64(IonSecureCmaAddToPoolEndFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.pool_total != 0) {
            target.appendInt32(IonSecureCmaAddToPoolEndFtraceEventWire.POOL_TOTAL_WIRE, self.pool_total);
        }
    }
};
pub const IonSecureCmaAddToPoolEndFtraceEventReader = struct {
    buf: gremlin.Reader,
    _is_prefetch: u32 = 0,
    _len: u64 = 0,
    _pool_total: i32 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonSecureCmaAddToPoolEndFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonSecureCmaAddToPoolEndFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonSecureCmaAddToPoolEndFtraceEventWire.IS_PREFETCH_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._is_prefetch = result.value;
                },
                IonSecureCmaAddToPoolEndFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IonSecureCmaAddToPoolEndFtraceEventWire.POOL_TOTAL_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._pool_total = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getIsPrefetch(self: *const IonSecureCmaAddToPoolEndFtraceEventReader) u32 {
        return self._is_prefetch;
    }
    pub inline fn getLen(self: *const IonSecureCmaAddToPoolEndFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getPoolTotal(self: *const IonSecureCmaAddToPoolEndFtraceEventReader) i32 {
        return self._pool_total;
    }
};
const IonSecureCmaAddToPoolStartFtraceEventWire = struct {
    const IS_PREFETCH_WIRE: gremlin.ProtoWireNumber = 1;
    const LEN_WIRE: gremlin.ProtoWireNumber = 2;
    const POOL_TOTAL_WIRE: gremlin.ProtoWireNumber = 3;
};
pub const IonSecureCmaAddToPoolStartFtraceEvent = struct {
    // fields
    is_prefetch: u32 = 0,
    len: u64 = 0,
    pool_total: i32 = 0,
    pub fn calcProtobufSize(self: *const IonSecureCmaAddToPoolStartFtraceEvent) usize {
        var res: usize = 0;
        if (self.is_prefetch != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAddToPoolStartFtraceEventWire.IS_PREFETCH_WIRE) + gremlin.sizes.sizeU32(self.is_prefetch);
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAddToPoolStartFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.pool_total != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAddToPoolStartFtraceEventWire.POOL_TOTAL_WIRE) + gremlin.sizes.sizeI32(self.pool_total);
        }
        return res;
    }
    pub fn encode(self: *const IonSecureCmaAddToPoolStartFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonSecureCmaAddToPoolStartFtraceEvent, target: *gremlin.Writer) void {
        if (self.is_prefetch != 0) {
            target.appendUint32(IonSecureCmaAddToPoolStartFtraceEventWire.IS_PREFETCH_WIRE, self.is_prefetch);
        }
        if (self.len != 0) {
            target.appendUint64(IonSecureCmaAddToPoolStartFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.pool_total != 0) {
            target.appendInt32(IonSecureCmaAddToPoolStartFtraceEventWire.POOL_TOTAL_WIRE, self.pool_total);
        }
    }
};
pub const IonSecureCmaAddToPoolStartFtraceEventReader = struct {
    buf: gremlin.Reader,
    _is_prefetch: u32 = 0,
    _len: u64 = 0,
    _pool_total: i32 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonSecureCmaAddToPoolStartFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonSecureCmaAddToPoolStartFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonSecureCmaAddToPoolStartFtraceEventWire.IS_PREFETCH_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._is_prefetch = result.value;
                },
                IonSecureCmaAddToPoolStartFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IonSecureCmaAddToPoolStartFtraceEventWire.POOL_TOTAL_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._pool_total = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getIsPrefetch(self: *const IonSecureCmaAddToPoolStartFtraceEventReader) u32 {
        return self._is_prefetch;
    }
    pub inline fn getLen(self: *const IonSecureCmaAddToPoolStartFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getPoolTotal(self: *const IonSecureCmaAddToPoolStartFtraceEventReader) i32 {
        return self._pool_total;
    }
};
const IonSecureCmaAllocateEndFtraceEventWire = struct {
    const ALIGN_WIRE: gremlin.ProtoWireNumber = 1;
    const FLAGS_WIRE: gremlin.ProtoWireNumber = 2;
    const HEAP_NAME_WIRE: gremlin.ProtoWireNumber = 3;
    const LEN_WIRE: gremlin.ProtoWireNumber = 4;
};
pub const IonSecureCmaAllocateEndFtraceEvent = struct {
    // fields
    align_: u64 = 0,
    flags: u64 = 0,
    heap_name: ?[]const u8 = null,
    len: u64 = 0,
    pub fn calcProtobufSize(self: *const IonSecureCmaAllocateEndFtraceEvent) usize {
        var res: usize = 0;
        if (self.align_ != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAllocateEndFtraceEventWire.ALIGN_WIRE) + gremlin.sizes.sizeU64(self.align_);
        }
        if (self.flags != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAllocateEndFtraceEventWire.FLAGS_WIRE) + gremlin.sizes.sizeU64(self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonSecureCmaAllocateEndFtraceEventWire.HEAP_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAllocateEndFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        return res;
    }
    pub fn encode(self: *const IonSecureCmaAllocateEndFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonSecureCmaAllocateEndFtraceEvent, target: *gremlin.Writer) void {
        if (self.align_ != 0) {
            target.appendUint64(IonSecureCmaAllocateEndFtraceEventWire.ALIGN_WIRE, self.align_);
        }
        if (self.flags != 0) {
            target.appendUint64(IonSecureCmaAllocateEndFtraceEventWire.FLAGS_WIRE, self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonSecureCmaAllocateEndFtraceEventWire.HEAP_NAME_WIRE, v);
            }
        }
        if (self.len != 0) {
            target.appendUint64(IonSecureCmaAllocateEndFtraceEventWire.LEN_WIRE, self.len);
        }
    }
};
pub const IonSecureCmaAllocateEndFtraceEventReader = struct {
    buf: gremlin.Reader,
    _align_: u64 = 0,
    _flags: u64 = 0,
    _heap_name: ?[]const u8 = null,
    _len: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonSecureCmaAllocateEndFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonSecureCmaAllocateEndFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonSecureCmaAllocateEndFtraceEventWire.ALIGN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._align_ = result.value;
                },
                IonSecureCmaAllocateEndFtraceEventWire.FLAGS_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._flags = result.value;
                },
                IonSecureCmaAllocateEndFtraceEventWire.HEAP_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._heap_name = result.value;
                },
                IonSecureCmaAllocateEndFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getAlign(self: *const IonSecureCmaAllocateEndFtraceEventReader) u64 {
        return self._align_;
    }
    pub inline fn getFlags(self: *const IonSecureCmaAllocateEndFtraceEventReader) u64 {
        return self._flags;
    }
    pub inline fn getHeapName(self: *const IonSecureCmaAllocateEndFtraceEventReader) []const u8 {
        return self._heap_name orelse &[_]u8{};
    }
    pub inline fn getLen(self: *const IonSecureCmaAllocateEndFtraceEventReader) u64 {
        return self._len;
    }
};
const IonSecureCmaAllocateStartFtraceEventWire = struct {
    const ALIGN_WIRE: gremlin.ProtoWireNumber = 1;
    const FLAGS_WIRE: gremlin.ProtoWireNumber = 2;
    const HEAP_NAME_WIRE: gremlin.ProtoWireNumber = 3;
    const LEN_WIRE: gremlin.ProtoWireNumber = 4;
};
pub const IonSecureCmaAllocateStartFtraceEvent = struct {
    // fields
    align_: u64 = 0,
    flags: u64 = 0,
    heap_name: ?[]const u8 = null,
    len: u64 = 0,
    pub fn calcProtobufSize(self: *const IonSecureCmaAllocateStartFtraceEvent) usize {
        var res: usize = 0;
        if (self.align_ != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAllocateStartFtraceEventWire.ALIGN_WIRE) + gremlin.sizes.sizeU64(self.align_);
        }
        if (self.flags != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAllocateStartFtraceEventWire.FLAGS_WIRE) + gremlin.sizes.sizeU64(self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonSecureCmaAllocateStartFtraceEventWire.HEAP_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaAllocateStartFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        return res;
    }
    pub fn encode(self: *const IonSecureCmaAllocateStartFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonSecureCmaAllocateStartFtraceEvent, target: *gremlin.Writer) void {
        if (self.align_ != 0) {
            target.appendUint64(IonSecureCmaAllocateStartFtraceEventWire.ALIGN_WIRE, self.align_);
        }
        if (self.flags != 0) {
            target.appendUint64(IonSecureCmaAllocateStartFtraceEventWire.FLAGS_WIRE, self.flags);
        }
        if (self.heap_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonSecureCmaAllocateStartFtraceEventWire.HEAP_NAME_WIRE, v);
            }
        }
        if (self.len != 0) {
            target.appendUint64(IonSecureCmaAllocateStartFtraceEventWire.LEN_WIRE, self.len);
        }
    }
};
pub const IonSecureCmaAllocateStartFtraceEventReader = struct {
    buf: gremlin.Reader,
    _align_: u64 = 0,
    _flags: u64 = 0,
    _heap_name: ?[]const u8 = null,
    _len: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonSecureCmaAllocateStartFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonSecureCmaAllocateStartFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonSecureCmaAllocateStartFtraceEventWire.ALIGN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._align_ = result.value;
                },
                IonSecureCmaAllocateStartFtraceEventWire.FLAGS_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._flags = result.value;
                },
                IonSecureCmaAllocateStartFtraceEventWire.HEAP_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._heap_name = result.value;
                },
                IonSecureCmaAllocateStartFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getAlign(self: *const IonSecureCmaAllocateStartFtraceEventReader) u64 {
        return self._align_;
    }
    pub inline fn getFlags(self: *const IonSecureCmaAllocateStartFtraceEventReader) u64 {
        return self._flags;
    }
    pub inline fn getHeapName(self: *const IonSecureCmaAllocateStartFtraceEventReader) []const u8 {
        return self._heap_name orelse &[_]u8{};
    }
    pub inline fn getLen(self: *const IonSecureCmaAllocateStartFtraceEventReader) u64 {
        return self._len;
    }
};
const IonSecureCmaShrinkPoolEndFtraceEventWire = struct {
    const DRAINED_SIZE_WIRE: gremlin.ProtoWireNumber = 1;
    const SKIPPED_SIZE_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const IonSecureCmaShrinkPoolEndFtraceEvent = struct {
    // fields
    drained_size: u64 = 0,
    skipped_size: u64 = 0,
    pub fn calcProtobufSize(self: *const IonSecureCmaShrinkPoolEndFtraceEvent) usize {
        var res: usize = 0;
        if (self.drained_size != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaShrinkPoolEndFtraceEventWire.DRAINED_SIZE_WIRE) + gremlin.sizes.sizeU64(self.drained_size);
        }
        if (self.skipped_size != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaShrinkPoolEndFtraceEventWire.SKIPPED_SIZE_WIRE) + gremlin.sizes.sizeU64(self.skipped_size);
        }
        return res;
    }
    pub fn encode(self: *const IonSecureCmaShrinkPoolEndFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonSecureCmaShrinkPoolEndFtraceEvent, target: *gremlin.Writer) void {
        if (self.drained_size != 0) {
            target.appendUint64(IonSecureCmaShrinkPoolEndFtraceEventWire.DRAINED_SIZE_WIRE, self.drained_size);
        }
        if (self.skipped_size != 0) {
            target.appendUint64(IonSecureCmaShrinkPoolEndFtraceEventWire.SKIPPED_SIZE_WIRE, self.skipped_size);
        }
    }
};
pub const IonSecureCmaShrinkPoolEndFtraceEventReader = struct {
    buf: gremlin.Reader,
    _drained_size: u64 = 0,
    _skipped_size: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonSecureCmaShrinkPoolEndFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonSecureCmaShrinkPoolEndFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonSecureCmaShrinkPoolEndFtraceEventWire.DRAINED_SIZE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._drained_size = result.value;
                },
                IonSecureCmaShrinkPoolEndFtraceEventWire.SKIPPED_SIZE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._skipped_size = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getDrainedSize(self: *const IonSecureCmaShrinkPoolEndFtraceEventReader) u64 {
        return self._drained_size;
    }
    pub inline fn getSkippedSize(self: *const IonSecureCmaShrinkPoolEndFtraceEventReader) u64 {
        return self._skipped_size;
    }
};
const IonSecureCmaShrinkPoolStartFtraceEventWire = struct {
    const DRAINED_SIZE_WIRE: gremlin.ProtoWireNumber = 1;
    const SKIPPED_SIZE_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const IonSecureCmaShrinkPoolStartFtraceEvent = struct {
    // fields
    drained_size: u64 = 0,
    skipped_size: u64 = 0,
    pub fn calcProtobufSize(self: *const IonSecureCmaShrinkPoolStartFtraceEvent) usize {
        var res: usize = 0;
        if (self.drained_size != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaShrinkPoolStartFtraceEventWire.DRAINED_SIZE_WIRE) + gremlin.sizes.sizeU64(self.drained_size);
        }
        if (self.skipped_size != 0) {
            res += gremlin.sizes.sizeWireNumber(IonSecureCmaShrinkPoolStartFtraceEventWire.SKIPPED_SIZE_WIRE) + gremlin.sizes.sizeU64(self.skipped_size);
        }
        return res;
    }
    pub fn encode(self: *const IonSecureCmaShrinkPoolStartFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonSecureCmaShrinkPoolStartFtraceEvent, target: *gremlin.Writer) void {
        if (self.drained_size != 0) {
            target.appendUint64(IonSecureCmaShrinkPoolStartFtraceEventWire.DRAINED_SIZE_WIRE, self.drained_size);
        }
        if (self.skipped_size != 0) {
            target.appendUint64(IonSecureCmaShrinkPoolStartFtraceEventWire.SKIPPED_SIZE_WIRE, self.skipped_size);
        }
    }
};
pub const IonSecureCmaShrinkPoolStartFtraceEventReader = struct {
    buf: gremlin.Reader,
    _drained_size: u64 = 0,
    _skipped_size: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonSecureCmaShrinkPoolStartFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonSecureCmaShrinkPoolStartFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonSecureCmaShrinkPoolStartFtraceEventWire.DRAINED_SIZE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._drained_size = result.value;
                },
                IonSecureCmaShrinkPoolStartFtraceEventWire.SKIPPED_SIZE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._skipped_size = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getDrainedSize(self: *const IonSecureCmaShrinkPoolStartFtraceEventReader) u64 {
        return self._drained_size;
    }
    pub inline fn getSkippedSize(self: *const IonSecureCmaShrinkPoolStartFtraceEventReader) u64 {
        return self._skipped_size;
    }
};
const KfreeFtraceEventWire = struct {
    const CALL_SITE_WIRE: gremlin.ProtoWireNumber = 1;
    const PTR_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const KfreeFtraceEvent = struct {
    // fields
    call_site: u64 = 0,
    ptr: u64 = 0,
    pub fn calcProtobufSize(self: *const KfreeFtraceEvent) usize {
        var res: usize = 0;
        if (self.call_site != 0) {
            res += gremlin.sizes.sizeWireNumber(KfreeFtraceEventWire.CALL_SITE_WIRE) + gremlin.sizes.sizeU64(self.call_site);
        }
        if (self.ptr != 0) {
            res += gremlin.sizes.sizeWireNumber(KfreeFtraceEventWire.PTR_WIRE) + gremlin.sizes.sizeU64(self.ptr);
        }
        return res;
    }
    pub fn encode(self: *const KfreeFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const KfreeFtraceEvent, target: *gremlin.Writer) void {
        if (self.call_site != 0) {
            target.appendUint64(KfreeFtraceEventWire.CALL_SITE_WIRE, self.call_site);
        }
        if (self.ptr != 0) {
            target.appendUint64(KfreeFtraceEventWire.PTR_WIRE, self.ptr);
        }
    }
};
pub const KfreeFtraceEventReader = struct {
    buf: gremlin.Reader,
    _call_site: u64 = 0,
    _ptr: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!KfreeFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = KfreeFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                KfreeFtraceEventWire.CALL_SITE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._call_site = result.value;
                },
                KfreeFtraceEventWire.PTR_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._ptr = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getCallSite(self: *const KfreeFtraceEventReader) u64 {
        return self._call_site;
    }
    pub inline fn getPtr(self: *const KfreeFtraceEventReader) u64 {
        return self._ptr;
    }
};
const KmallocFtraceEventWire = struct {
    const BYTES_ALLOC_WIRE: gremlin.ProtoWireNumber = 1;
    const BYTES_REQ_WIRE: gremlin.ProtoWireNumber = 2;
    const CALL_SITE_WIRE: gremlin.ProtoWireNumber = 3;
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 4;
    const PTR_WIRE: gremlin.ProtoWireNumber = 5;
};
pub const KmallocFtraceEvent = struct {
    // fields
    bytes_alloc: u64 = 0,
    bytes_req: u64 = 0,
    call_site: u64 = 0,
    gfp_flags: u32 = 0,
    ptr: u64 = 0,
    pub fn calcProtobufSize(self: *const KmallocFtraceEvent) usize {
        var res: usize = 0;
        if (self.bytes_alloc != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocFtraceEventWire.BYTES_ALLOC_WIRE) + gremlin.sizes.sizeU64(self.bytes_alloc);
        }
        if (self.bytes_req != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocFtraceEventWire.BYTES_REQ_WIRE) + gremlin.sizes.sizeU64(self.bytes_req);
        }
        if (self.call_site != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocFtraceEventWire.CALL_SITE_WIRE) + gremlin.sizes.sizeU64(self.call_site);
        }
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.ptr != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocFtraceEventWire.PTR_WIRE) + gremlin.sizes.sizeU64(self.ptr);
        }
        return res;
    }
    pub fn encode(self: *const KmallocFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const KmallocFtraceEvent, target: *gremlin.Writer) void {
        if (self.bytes_alloc != 0) {
            target.appendUint64(KmallocFtraceEventWire.BYTES_ALLOC_WIRE, self.bytes_alloc);
        }
        if (self.bytes_req != 0) {
            target.appendUint64(KmallocFtraceEventWire.BYTES_REQ_WIRE, self.bytes_req);
        }
        if (self.call_site != 0) {
            target.appendUint64(KmallocFtraceEventWire.CALL_SITE_WIRE, self.call_site);
        }
        if (self.gfp_flags != 0) {
            target.appendUint32(KmallocFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.ptr != 0) {
            target.appendUint64(KmallocFtraceEventWire.PTR_WIRE, self.ptr);
        }
    }
};
pub const KmallocFtraceEventReader = struct {
    buf: gremlin.Reader,
    _bytes_alloc: u64 = 0,
    _bytes_req: u64 = 0,
    _call_site: u64 = 0,
    _gfp_flags: u32 = 0,
    _ptr: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!KmallocFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = KmallocFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                KmallocFtraceEventWire.BYTES_ALLOC_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._bytes_alloc = result.value;
                },
                KmallocFtraceEventWire.BYTES_REQ_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._bytes_req = result.value;
                },
                KmallocFtraceEventWire.CALL_SITE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._call_site = result.value;
                },
                KmallocFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                KmallocFtraceEventWire.PTR_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._ptr = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getBytesAlloc(self: *const KmallocFtraceEventReader) u64 {
        return self._bytes_alloc;
    }
    pub inline fn getBytesReq(self: *const KmallocFtraceEventReader) u64 {
        return self._bytes_req;
    }
    pub inline fn getCallSite(self: *const KmallocFtraceEventReader) u64 {
        return self._call_site;
    }
    pub inline fn getGfpFlags(self: *const KmallocFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getPtr(self: *const KmallocFtraceEventReader) u64 {
        return self._ptr;
    }
};
const KmallocNodeFtraceEventWire = struct {
    const BYTES_ALLOC_WIRE: gremlin.ProtoWireNumber = 1;
    const BYTES_REQ_WIRE: gremlin.ProtoWireNumber = 2;
    const CALL_SITE_WIRE: gremlin.ProtoWireNumber = 3;
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 4;
    const NODE_WIRE: gremlin.ProtoWireNumber = 5;
    const PTR_WIRE: gremlin.ProtoWireNumber = 6;
};
pub const KmallocNodeFtraceEvent = struct {
    // fields
    bytes_alloc: u64 = 0,
    bytes_req: u64 = 0,
    call_site: u64 = 0,
    gfp_flags: u32 = 0,
    node: i32 = 0,
    ptr: u64 = 0,
    pub fn calcProtobufSize(self: *const KmallocNodeFtraceEvent) usize {
        var res: usize = 0;
        if (self.bytes_alloc != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocNodeFtraceEventWire.BYTES_ALLOC_WIRE) + gremlin.sizes.sizeU64(self.bytes_alloc);
        }
        if (self.bytes_req != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocNodeFtraceEventWire.BYTES_REQ_WIRE) + gremlin.sizes.sizeU64(self.bytes_req);
        }
        if (self.call_site != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocNodeFtraceEventWire.CALL_SITE_WIRE) + gremlin.sizes.sizeU64(self.call_site);
        }
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocNodeFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.node != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocNodeFtraceEventWire.NODE_WIRE) + gremlin.sizes.sizeI32(self.node);
        }
        if (self.ptr != 0) {
            res += gremlin.sizes.sizeWireNumber(KmallocNodeFtraceEventWire.PTR_WIRE) + gremlin.sizes.sizeU64(self.ptr);
        }
        return res;
    }
    pub fn encode(self: *const KmallocNodeFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const KmallocNodeFtraceEvent, target: *gremlin.Writer) void {
        if (self.bytes_alloc != 0) {
            target.appendUint64(KmallocNodeFtraceEventWire.BYTES_ALLOC_WIRE, self.bytes_alloc);
        }
        if (self.bytes_req != 0) {
            target.appendUint64(KmallocNodeFtraceEventWire.BYTES_REQ_WIRE, self.bytes_req);
        }
        if (self.call_site != 0) {
            target.appendUint64(KmallocNodeFtraceEventWire.CALL_SITE_WIRE, self.call_site);
        }
        if (self.gfp_flags != 0) {
            target.appendUint32(KmallocNodeFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.node != 0) {
            target.appendInt32(KmallocNodeFtraceEventWire.NODE_WIRE, self.node);
        }
        if (self.ptr != 0) {
            target.appendUint64(KmallocNodeFtraceEventWire.PTR_WIRE, self.ptr);
        }
    }
};
pub const KmallocNodeFtraceEventReader = struct {
    buf: gremlin.Reader,
    _bytes_alloc: u64 = 0,
    _bytes_req: u64 = 0,
    _call_site: u64 = 0,
    _gfp_flags: u32 = 0,
    _node: i32 = 0,
    _ptr: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!KmallocNodeFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = KmallocNodeFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                KmallocNodeFtraceEventWire.BYTES_ALLOC_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._bytes_alloc = result.value;
                },
                KmallocNodeFtraceEventWire.BYTES_REQ_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._bytes_req = result.value;
                },
                KmallocNodeFtraceEventWire.CALL_SITE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._call_site = result.value;
                },
                KmallocNodeFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                KmallocNodeFtraceEventWire.NODE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._node = result.value;
                },
                KmallocNodeFtraceEventWire.PTR_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._ptr = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getBytesAlloc(self: *const KmallocNodeFtraceEventReader) u64 {
        return self._bytes_alloc;
    }
    pub inline fn getBytesReq(self: *const KmallocNodeFtraceEventReader) u64 {
        return self._bytes_req;
    }
    pub inline fn getCallSite(self: *const KmallocNodeFtraceEventReader) u64 {
        return self._call_site;
    }
    pub inline fn getGfpFlags(self: *const KmallocNodeFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getNode(self: *const KmallocNodeFtraceEventReader) i32 {
        return self._node;
    }
    pub inline fn getPtr(self: *const KmallocNodeFtraceEventReader) u64 {
        return self._ptr;
    }
};
const KmemCacheAllocFtraceEventWire = struct {
    const BYTES_ALLOC_WIRE: gremlin.ProtoWireNumber = 1;
    const BYTES_REQ_WIRE: gremlin.ProtoWireNumber = 2;
    const CALL_SITE_WIRE: gremlin.ProtoWireNumber = 3;
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 4;
    const PTR_WIRE: gremlin.ProtoWireNumber = 5;
};
pub const KmemCacheAllocFtraceEvent = struct {
    // fields
    bytes_alloc: u64 = 0,
    bytes_req: u64 = 0,
    call_site: u64 = 0,
    gfp_flags: u32 = 0,
    ptr: u64 = 0,
    pub fn calcProtobufSize(self: *const KmemCacheAllocFtraceEvent) usize {
        var res: usize = 0;
        if (self.bytes_alloc != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocFtraceEventWire.BYTES_ALLOC_WIRE) + gremlin.sizes.sizeU64(self.bytes_alloc);
        }
        if (self.bytes_req != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocFtraceEventWire.BYTES_REQ_WIRE) + gremlin.sizes.sizeU64(self.bytes_req);
        }
        if (self.call_site != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocFtraceEventWire.CALL_SITE_WIRE) + gremlin.sizes.sizeU64(self.call_site);
        }
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.ptr != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocFtraceEventWire.PTR_WIRE) + gremlin.sizes.sizeU64(self.ptr);
        }
        return res;
    }
    pub fn encode(self: *const KmemCacheAllocFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const KmemCacheAllocFtraceEvent, target: *gremlin.Writer) void {
        if (self.bytes_alloc != 0) {
            target.appendUint64(KmemCacheAllocFtraceEventWire.BYTES_ALLOC_WIRE, self.bytes_alloc);
        }
        if (self.bytes_req != 0) {
            target.appendUint64(KmemCacheAllocFtraceEventWire.BYTES_REQ_WIRE, self.bytes_req);
        }
        if (self.call_site != 0) {
            target.appendUint64(KmemCacheAllocFtraceEventWire.CALL_SITE_WIRE, self.call_site);
        }
        if (self.gfp_flags != 0) {
            target.appendUint32(KmemCacheAllocFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.ptr != 0) {
            target.appendUint64(KmemCacheAllocFtraceEventWire.PTR_WIRE, self.ptr);
        }
    }
};
pub const KmemCacheAllocFtraceEventReader = struct {
    buf: gremlin.Reader,
    _bytes_alloc: u64 = 0,
    _bytes_req: u64 = 0,
    _call_site: u64 = 0,
    _gfp_flags: u32 = 0,
    _ptr: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!KmemCacheAllocFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = KmemCacheAllocFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                KmemCacheAllocFtraceEventWire.BYTES_ALLOC_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._bytes_alloc = result.value;
                },
                KmemCacheAllocFtraceEventWire.BYTES_REQ_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._bytes_req = result.value;
                },
                KmemCacheAllocFtraceEventWire.CALL_SITE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._call_site = result.value;
                },
                KmemCacheAllocFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                KmemCacheAllocFtraceEventWire.PTR_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._ptr = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getBytesAlloc(self: *const KmemCacheAllocFtraceEventReader) u64 {
        return self._bytes_alloc;
    }
    pub inline fn getBytesReq(self: *const KmemCacheAllocFtraceEventReader) u64 {
        return self._bytes_req;
    }
    pub inline fn getCallSite(self: *const KmemCacheAllocFtraceEventReader) u64 {
        return self._call_site;
    }
    pub inline fn getGfpFlags(self: *const KmemCacheAllocFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getPtr(self: *const KmemCacheAllocFtraceEventReader) u64 {
        return self._ptr;
    }
};
const KmemCacheAllocNodeFtraceEventWire = struct {
    const BYTES_ALLOC_WIRE: gremlin.ProtoWireNumber = 1;
    const BYTES_REQ_WIRE: gremlin.ProtoWireNumber = 2;
    const CALL_SITE_WIRE: gremlin.ProtoWireNumber = 3;
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 4;
    const NODE_WIRE: gremlin.ProtoWireNumber = 5;
    const PTR_WIRE: gremlin.ProtoWireNumber = 6;
};
pub const KmemCacheAllocNodeFtraceEvent = struct {
    // fields
    bytes_alloc: u64 = 0,
    bytes_req: u64 = 0,
    call_site: u64 = 0,
    gfp_flags: u32 = 0,
    node: i32 = 0,
    ptr: u64 = 0,
    pub fn calcProtobufSize(self: *const KmemCacheAllocNodeFtraceEvent) usize {
        var res: usize = 0;
        if (self.bytes_alloc != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocNodeFtraceEventWire.BYTES_ALLOC_WIRE) + gremlin.sizes.sizeU64(self.bytes_alloc);
        }
        if (self.bytes_req != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocNodeFtraceEventWire.BYTES_REQ_WIRE) + gremlin.sizes.sizeU64(self.bytes_req);
        }
        if (self.call_site != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocNodeFtraceEventWire.CALL_SITE_WIRE) + gremlin.sizes.sizeU64(self.call_site);
        }
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocNodeFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.node != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocNodeFtraceEventWire.NODE_WIRE) + gremlin.sizes.sizeI32(self.node);
        }
        if (self.ptr != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheAllocNodeFtraceEventWire.PTR_WIRE) + gremlin.sizes.sizeU64(self.ptr);
        }
        return res;
    }
    pub fn encode(self: *const KmemCacheAllocNodeFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const KmemCacheAllocNodeFtraceEvent, target: *gremlin.Writer) void {
        if (self.bytes_alloc != 0) {
            target.appendUint64(KmemCacheAllocNodeFtraceEventWire.BYTES_ALLOC_WIRE, self.bytes_alloc);
        }
        if (self.bytes_req != 0) {
            target.appendUint64(KmemCacheAllocNodeFtraceEventWire.BYTES_REQ_WIRE, self.bytes_req);
        }
        if (self.call_site != 0) {
            target.appendUint64(KmemCacheAllocNodeFtraceEventWire.CALL_SITE_WIRE, self.call_site);
        }
        if (self.gfp_flags != 0) {
            target.appendUint32(KmemCacheAllocNodeFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.node != 0) {
            target.appendInt32(KmemCacheAllocNodeFtraceEventWire.NODE_WIRE, self.node);
        }
        if (self.ptr != 0) {
            target.appendUint64(KmemCacheAllocNodeFtraceEventWire.PTR_WIRE, self.ptr);
        }
    }
};
pub const KmemCacheAllocNodeFtraceEventReader = struct {
    buf: gremlin.Reader,
    _bytes_alloc: u64 = 0,
    _bytes_req: u64 = 0,
    _call_site: u64 = 0,
    _gfp_flags: u32 = 0,
    _node: i32 = 0,
    _ptr: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!KmemCacheAllocNodeFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = KmemCacheAllocNodeFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                KmemCacheAllocNodeFtraceEventWire.BYTES_ALLOC_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._bytes_alloc = result.value;
                },
                KmemCacheAllocNodeFtraceEventWire.BYTES_REQ_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._bytes_req = result.value;
                },
                KmemCacheAllocNodeFtraceEventWire.CALL_SITE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._call_site = result.value;
                },
                KmemCacheAllocNodeFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                KmemCacheAllocNodeFtraceEventWire.NODE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._node = result.value;
                },
                KmemCacheAllocNodeFtraceEventWire.PTR_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._ptr = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getBytesAlloc(self: *const KmemCacheAllocNodeFtraceEventReader) u64 {
        return self._bytes_alloc;
    }
    pub inline fn getBytesReq(self: *const KmemCacheAllocNodeFtraceEventReader) u64 {
        return self._bytes_req;
    }
    pub inline fn getCallSite(self: *const KmemCacheAllocNodeFtraceEventReader) u64 {
        return self._call_site;
    }
    pub inline fn getGfpFlags(self: *const KmemCacheAllocNodeFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getNode(self: *const KmemCacheAllocNodeFtraceEventReader) i32 {
        return self._node;
    }
    pub inline fn getPtr(self: *const KmemCacheAllocNodeFtraceEventReader) u64 {
        return self._ptr;
    }
};
const KmemCacheFreeFtraceEventWire = struct {
    const CALL_SITE_WIRE: gremlin.ProtoWireNumber = 1;
    const PTR_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const KmemCacheFreeFtraceEvent = struct {
    // fields
    call_site: u64 = 0,
    ptr: u64 = 0,
    pub fn calcProtobufSize(self: *const KmemCacheFreeFtraceEvent) usize {
        var res: usize = 0;
        if (self.call_site != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheFreeFtraceEventWire.CALL_SITE_WIRE) + gremlin.sizes.sizeU64(self.call_site);
        }
        if (self.ptr != 0) {
            res += gremlin.sizes.sizeWireNumber(KmemCacheFreeFtraceEventWire.PTR_WIRE) + gremlin.sizes.sizeU64(self.ptr);
        }
        return res;
    }
    pub fn encode(self: *const KmemCacheFreeFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const KmemCacheFreeFtraceEvent, target: *gremlin.Writer) void {
        if (self.call_site != 0) {
            target.appendUint64(KmemCacheFreeFtraceEventWire.CALL_SITE_WIRE, self.call_site);
        }
        if (self.ptr != 0) {
            target.appendUint64(KmemCacheFreeFtraceEventWire.PTR_WIRE, self.ptr);
        }
    }
};
pub const KmemCacheFreeFtraceEventReader = struct {
    buf: gremlin.Reader,
    _call_site: u64 = 0,
    _ptr: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!KmemCacheFreeFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = KmemCacheFreeFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                KmemCacheFreeFtraceEventWire.CALL_SITE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._call_site = result.value;
                },
                KmemCacheFreeFtraceEventWire.PTR_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._ptr = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getCallSite(self: *const KmemCacheFreeFtraceEventReader) u64 {
        return self._call_site;
    }
    pub inline fn getPtr(self: *const KmemCacheFreeFtraceEventReader) u64 {
        return self._ptr;
    }
};
const MigratePagesEndFtraceEventWire = struct {
    const MODE_WIRE: gremlin.ProtoWireNumber = 1;
};
pub const MigratePagesEndFtraceEvent = struct {
    // fields
    mode: i32 = 0,
    pub fn calcProtobufSize(self: *const MigratePagesEndFtraceEvent) usize {
        var res: usize = 0;
        if (self.mode != 0) {
            res += gremlin.sizes.sizeWireNumber(MigratePagesEndFtraceEventWire.MODE_WIRE) + gremlin.sizes.sizeI32(self.mode);
        }
        return res;
    }
    pub fn encode(self: *const MigratePagesEndFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const MigratePagesEndFtraceEvent, target: *gremlin.Writer) void {
        if (self.mode != 0) {
            target.appendInt32(MigratePagesEndFtraceEventWire.MODE_WIRE, self.mode);
        }
    }
};
pub const MigratePagesEndFtraceEventReader = struct {
    buf: gremlin.Reader,
    _mode: i32 = 0,
    pub fn init(src: []const u8) gremlin.Error!MigratePagesEndFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = MigratePagesEndFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                MigratePagesEndFtraceEventWire.MODE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._mode = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getMode(self: *const MigratePagesEndFtraceEventReader) i32 {
        return self._mode;
    }
};
const MigratePagesStartFtraceEventWire = struct {
    const MODE_WIRE: gremlin.ProtoWireNumber = 1;
};
pub const MigratePagesStartFtraceEvent = struct {
    // fields
    mode: i32 = 0,
    pub fn calcProtobufSize(self: *const MigratePagesStartFtraceEvent) usize {
        var res: usize = 0;
        if (self.mode != 0) {
            res += gremlin.sizes.sizeWireNumber(MigratePagesStartFtraceEventWire.MODE_WIRE) + gremlin.sizes.sizeI32(self.mode);
        }
        return res;
    }
    pub fn encode(self: *const MigratePagesStartFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const MigratePagesStartFtraceEvent, target: *gremlin.Writer) void {
        if (self.mode != 0) {
            target.appendInt32(MigratePagesStartFtraceEventWire.MODE_WIRE, self.mode);
        }
    }
};
pub const MigratePagesStartFtraceEventReader = struct {
    buf: gremlin.Reader,
    _mode: i32 = 0,
    pub fn init(src: []const u8) gremlin.Error!MigratePagesStartFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = MigratePagesStartFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                MigratePagesStartFtraceEventWire.MODE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._mode = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getMode(self: *const MigratePagesStartFtraceEventReader) i32 {
        return self._mode;
    }
};
const MigrateRetryFtraceEventWire = struct {
    const TRIES_WIRE: gremlin.ProtoWireNumber = 1;
};
pub const MigrateRetryFtraceEvent = struct {
    // fields
    tries: i32 = 0,
    pub fn calcProtobufSize(self: *const MigrateRetryFtraceEvent) usize {
        var res: usize = 0;
        if (self.tries != 0) {
            res += gremlin.sizes.sizeWireNumber(MigrateRetryFtraceEventWire.TRIES_WIRE) + gremlin.sizes.sizeI32(self.tries);
        }
        return res;
    }
    pub fn encode(self: *const MigrateRetryFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const MigrateRetryFtraceEvent, target: *gremlin.Writer) void {
        if (self.tries != 0) {
            target.appendInt32(MigrateRetryFtraceEventWire.TRIES_WIRE, self.tries);
        }
    }
};
pub const MigrateRetryFtraceEventReader = struct {
    buf: gremlin.Reader,
    _tries: i32 = 0,
    pub fn init(src: []const u8) gremlin.Error!MigrateRetryFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = MigrateRetryFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                MigrateRetryFtraceEventWire.TRIES_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._tries = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getTries(self: *const MigrateRetryFtraceEventReader) i32 {
        return self._tries;
    }
};
const MmPageAllocFtraceEventWire = struct {
    const GFP_FLAGS_WIRE: gremlin.ProtoWireNumber = 1;
    const MIGRATETYPE_WIRE: gremlin.ProtoWireNumber = 2;
    const ORDER_WIRE: gremlin.ProtoWireNumber = 3;
    const PAGE_WIRE: gremlin.ProtoWireNumber = 4;
    const PFN_WIRE: gremlin.ProtoWireNumber = 5;
};
pub const MmPageAllocFtraceEvent = struct {
    // fields
    gfp_flags: u32 = 0,
    migratetype: i32 = 0,
    order: u32 = 0,
    page: u64 = 0,
    pfn: u64 = 0,
    pub fn calcProtobufSize(self: *const MmPageAllocFtraceEvent) usize {
        var res: usize = 0;
        if (self.gfp_flags != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocFtraceEventWire.GFP_FLAGS_WIRE) + gremlin.sizes.sizeU32(self.gfp_flags);
        }
        if (self.migratetype != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocFtraceEventWire.MIGRATETYPE_WIRE) + gremlin.sizes.sizeI32(self.migratetype);
        }
        if (self.order != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocFtraceEventWire.ORDER_WIRE) + gremlin.sizes.sizeU32(self.order);
        }
        if (self.page != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocFtraceEventWire.PAGE_WIRE) + gremlin.sizes.sizeU64(self.page);
        }
        if (self.pfn != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocFtraceEventWire.PFN_WIRE) + gremlin.sizes.sizeU64(self.pfn);
        }
        return res;
    }
    pub fn encode(self: *const MmPageAllocFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const MmPageAllocFtraceEvent, target: *gremlin.Writer) void {
        if (self.gfp_flags != 0) {
            target.appendUint32(MmPageAllocFtraceEventWire.GFP_FLAGS_WIRE, self.gfp_flags);
        }
        if (self.migratetype != 0) {
            target.appendInt32(MmPageAllocFtraceEventWire.MIGRATETYPE_WIRE, self.migratetype);
        }
        if (self.order != 0) {
            target.appendUint32(MmPageAllocFtraceEventWire.ORDER_WIRE, self.order);
        }
        if (self.page != 0) {
            target.appendUint64(MmPageAllocFtraceEventWire.PAGE_WIRE, self.page);
        }
        if (self.pfn != 0) {
            target.appendUint64(MmPageAllocFtraceEventWire.PFN_WIRE, self.pfn);
        }
    }
};
pub const MmPageAllocFtraceEventReader = struct {
    buf: gremlin.Reader,
    _gfp_flags: u32 = 0,
    _migratetype: i32 = 0,
    _order: u32 = 0,
    _page: u64 = 0,
    _pfn: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!MmPageAllocFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = MmPageAllocFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                MmPageAllocFtraceEventWire.GFP_FLAGS_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._gfp_flags = result.value;
                },
                MmPageAllocFtraceEventWire.MIGRATETYPE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._migratetype = result.value;
                },
                MmPageAllocFtraceEventWire.ORDER_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._order = result.value;
                },
                MmPageAllocFtraceEventWire.PAGE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._page = result.value;
                },
                MmPageAllocFtraceEventWire.PFN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._pfn = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getGfpFlags(self: *const MmPageAllocFtraceEventReader) u32 {
        return self._gfp_flags;
    }
    pub inline fn getMigratetype(self: *const MmPageAllocFtraceEventReader) i32 {
        return self._migratetype;
    }
    pub inline fn getOrder(self: *const MmPageAllocFtraceEventReader) u32 {
        return self._order;
    }
    pub inline fn getPage(self: *const MmPageAllocFtraceEventReader) u64 {
        return self._page;
    }
    pub inline fn getPfn(self: *const MmPageAllocFtraceEventReader) u64 {
        return self._pfn;
    }
};
const MmPageAllocExtfragFtraceEventWire = struct {
    const ALLOC_MIGRATETYPE_WIRE: gremlin.ProtoWireNumber = 1;
    const ALLOC_ORDER_WIRE: gremlin.ProtoWireNumber = 2;
    const FALLBACK_MIGRATETYPE_WIRE: gremlin.ProtoWireNumber = 3;
    const FALLBACK_ORDER_WIRE: gremlin.ProtoWireNumber = 4;
    const PAGE_WIRE: gremlin.ProtoWireNumber = 5;
    const CHANGE_OWNERSHIP_WIRE: gremlin.ProtoWireNumber = 6;
    const PFN_WIRE: gremlin.ProtoWireNumber = 7;
};
pub const MmPageAllocExtfragFtraceEvent = struct {
    // fields
    alloc_migratetype: i32 = 0,
    alloc_order: i32 = 0,
    fallback_migratetype: i32 = 0,
    fallback_order: i32 = 0,
    page: u64 = 0,
    change_ownership: i32 = 0,
    pfn: u64 = 0,
    pub fn calcProtobufSize(self: *const MmPageAllocExtfragFtraceEvent) usize {
        var res: usize = 0;
        if (self.alloc_migratetype != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocExtfragFtraceEventWire.ALLOC_MIGRATETYPE_WIRE) + gremlin.sizes.sizeI32(self.alloc_migratetype);
        }
        if (self.alloc_order != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocExtfragFtraceEventWire.ALLOC_ORDER_WIRE) + gremlin.sizes.sizeI32(self.alloc_order);
        }
        if (self.fallback_migratetype != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocExtfragFtraceEventWire.FALLBACK_MIGRATETYPE_WIRE) + gremlin.sizes.sizeI32(self.fallback_migratetype);
        }
        if (self.fallback_order != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocExtfragFtraceEventWire.FALLBACK_ORDER_WIRE) + gremlin.sizes.sizeI32(self.fallback_order);
        }
        if (self.page != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocExtfragFtraceEventWire.PAGE_WIRE) + gremlin.sizes.sizeU64(self.page);
        }
        if (self.change_ownership != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocExtfragFtraceEventWire.CHANGE_OWNERSHIP_WIRE) + gremlin.sizes.sizeI32(self.change_ownership);
        }
        if (self.pfn != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocExtfragFtraceEventWire.PFN_WIRE) + gremlin.sizes.sizeU64(self.pfn);
        }
        return res;
    }
    pub fn encode(self: *const MmPageAllocExtfragFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const MmPageAllocExtfragFtraceEvent, target: *gremlin.Writer) void {
        if (self.alloc_migratetype != 0) {
            target.appendInt32(MmPageAllocExtfragFtraceEventWire.ALLOC_MIGRATETYPE_WIRE, self.alloc_migratetype);
        }
        if (self.alloc_order != 0) {
            target.appendInt32(MmPageAllocExtfragFtraceEventWire.ALLOC_ORDER_WIRE, self.alloc_order);
        }
        if (self.fallback_migratetype != 0) {
            target.appendInt32(MmPageAllocExtfragFtraceEventWire.FALLBACK_MIGRATETYPE_WIRE, self.fallback_migratetype);
        }
        if (self.fallback_order != 0) {
            target.appendInt32(MmPageAllocExtfragFtraceEventWire.FALLBACK_ORDER_WIRE, self.fallback_order);
        }
        if (self.page != 0) {
            target.appendUint64(MmPageAllocExtfragFtraceEventWire.PAGE_WIRE, self.page);
        }
        if (self.change_ownership != 0) {
            target.appendInt32(MmPageAllocExtfragFtraceEventWire.CHANGE_OWNERSHIP_WIRE, self.change_ownership);
        }
        if (self.pfn != 0) {
            target.appendUint64(MmPageAllocExtfragFtraceEventWire.PFN_WIRE, self.pfn);
        }
    }
};
pub const MmPageAllocExtfragFtraceEventReader = struct {
    buf: gremlin.Reader,
    _alloc_migratetype: i32 = 0,
    _alloc_order: i32 = 0,
    _fallback_migratetype: i32 = 0,
    _fallback_order: i32 = 0,
    _page: u64 = 0,
    _change_ownership: i32 = 0,
    _pfn: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!MmPageAllocExtfragFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = MmPageAllocExtfragFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                MmPageAllocExtfragFtraceEventWire.ALLOC_MIGRATETYPE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._alloc_migratetype = result.value;
                },
                MmPageAllocExtfragFtraceEventWire.ALLOC_ORDER_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._alloc_order = result.value;
                },
                MmPageAllocExtfragFtraceEventWire.FALLBACK_MIGRATETYPE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._fallback_migratetype = result.value;
                },
                MmPageAllocExtfragFtraceEventWire.FALLBACK_ORDER_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._fallback_order = result.value;
                },
                MmPageAllocExtfragFtraceEventWire.PAGE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._page = result.value;
                },
                MmPageAllocExtfragFtraceEventWire.CHANGE_OWNERSHIP_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._change_ownership = result.value;
                },
                MmPageAllocExtfragFtraceEventWire.PFN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._pfn = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getAllocMigratetype(self: *const MmPageAllocExtfragFtraceEventReader) i32 {
        return self._alloc_migratetype;
    }
    pub inline fn getAllocOrder(self: *const MmPageAllocExtfragFtraceEventReader) i32 {
        return self._alloc_order;
    }
    pub inline fn getFallbackMigratetype(self: *const MmPageAllocExtfragFtraceEventReader) i32 {
        return self._fallback_migratetype;
    }
    pub inline fn getFallbackOrder(self: *const MmPageAllocExtfragFtraceEventReader) i32 {
        return self._fallback_order;
    }
    pub inline fn getPage(self: *const MmPageAllocExtfragFtraceEventReader) u64 {
        return self._page;
    }
    pub inline fn getChangeOwnership(self: *const MmPageAllocExtfragFtraceEventReader) i32 {
        return self._change_ownership;
    }
    pub inline fn getPfn(self: *const MmPageAllocExtfragFtraceEventReader) u64 {
        return self._pfn;
    }
};
const MmPageAllocZoneLockedFtraceEventWire = struct {
    const MIGRATETYPE_WIRE: gremlin.ProtoWireNumber = 1;
    const ORDER_WIRE: gremlin.ProtoWireNumber = 2;
    const PAGE_WIRE: gremlin.ProtoWireNumber = 3;
    const PFN_WIRE: gremlin.ProtoWireNumber = 4;
};
pub const MmPageAllocZoneLockedFtraceEvent = struct {
    // fields
    migratetype: i32 = 0,
    order: u32 = 0,
    page: u64 = 0,
    pfn: u64 = 0,
    pub fn calcProtobufSize(self: *const MmPageAllocZoneLockedFtraceEvent) usize {
        var res: usize = 0;
        if (self.migratetype != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocZoneLockedFtraceEventWire.MIGRATETYPE_WIRE) + gremlin.sizes.sizeI32(self.migratetype);
        }
        if (self.order != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocZoneLockedFtraceEventWire.ORDER_WIRE) + gremlin.sizes.sizeU32(self.order);
        }
        if (self.page != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocZoneLockedFtraceEventWire.PAGE_WIRE) + gremlin.sizes.sizeU64(self.page);
        }
        if (self.pfn != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageAllocZoneLockedFtraceEventWire.PFN_WIRE) + gremlin.sizes.sizeU64(self.pfn);
        }
        return res;
    }
    pub fn encode(self: *const MmPageAllocZoneLockedFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const MmPageAllocZoneLockedFtraceEvent, target: *gremlin.Writer) void {
        if (self.migratetype != 0) {
            target.appendInt32(MmPageAllocZoneLockedFtraceEventWire.MIGRATETYPE_WIRE, self.migratetype);
        }
        if (self.order != 0) {
            target.appendUint32(MmPageAllocZoneLockedFtraceEventWire.ORDER_WIRE, self.order);
        }
        if (self.page != 0) {
            target.appendUint64(MmPageAllocZoneLockedFtraceEventWire.PAGE_WIRE, self.page);
        }
        if (self.pfn != 0) {
            target.appendUint64(MmPageAllocZoneLockedFtraceEventWire.PFN_WIRE, self.pfn);
        }
    }
};
pub const MmPageAllocZoneLockedFtraceEventReader = struct {
    buf: gremlin.Reader,
    _migratetype: i32 = 0,
    _order: u32 = 0,
    _page: u64 = 0,
    _pfn: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!MmPageAllocZoneLockedFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = MmPageAllocZoneLockedFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                MmPageAllocZoneLockedFtraceEventWire.MIGRATETYPE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._migratetype = result.value;
                },
                MmPageAllocZoneLockedFtraceEventWire.ORDER_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._order = result.value;
                },
                MmPageAllocZoneLockedFtraceEventWire.PAGE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._page = result.value;
                },
                MmPageAllocZoneLockedFtraceEventWire.PFN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._pfn = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getMigratetype(self: *const MmPageAllocZoneLockedFtraceEventReader) i32 {
        return self._migratetype;
    }
    pub inline fn getOrder(self: *const MmPageAllocZoneLockedFtraceEventReader) u32 {
        return self._order;
    }
    pub inline fn getPage(self: *const MmPageAllocZoneLockedFtraceEventReader) u64 {
        return self._page;
    }
    pub inline fn getPfn(self: *const MmPageAllocZoneLockedFtraceEventReader) u64 {
        return self._pfn;
    }
};
const MmPageFreeFtraceEventWire = struct {
    const ORDER_WIRE: gremlin.ProtoWireNumber = 1;
    const PAGE_WIRE: gremlin.ProtoWireNumber = 2;
    const PFN_WIRE: gremlin.ProtoWireNumber = 3;
};
pub const MmPageFreeFtraceEvent = struct {
    // fields
    order: u32 = 0,
    page: u64 = 0,
    pfn: u64 = 0,
    pub fn calcProtobufSize(self: *const MmPageFreeFtraceEvent) usize {
        var res: usize = 0;
        if (self.order != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageFreeFtraceEventWire.ORDER_WIRE) + gremlin.sizes.sizeU32(self.order);
        }
        if (self.page != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageFreeFtraceEventWire.PAGE_WIRE) + gremlin.sizes.sizeU64(self.page);
        }
        if (self.pfn != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageFreeFtraceEventWire.PFN_WIRE) + gremlin.sizes.sizeU64(self.pfn);
        }
        return res;
    }
    pub fn encode(self: *const MmPageFreeFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const MmPageFreeFtraceEvent, target: *gremlin.Writer) void {
        if (self.order != 0) {
            target.appendUint32(MmPageFreeFtraceEventWire.ORDER_WIRE, self.order);
        }
        if (self.page != 0) {
            target.appendUint64(MmPageFreeFtraceEventWire.PAGE_WIRE, self.page);
        }
        if (self.pfn != 0) {
            target.appendUint64(MmPageFreeFtraceEventWire.PFN_WIRE, self.pfn);
        }
    }
};
pub const MmPageFreeFtraceEventReader = struct {
    buf: gremlin.Reader,
    _order: u32 = 0,
    _page: u64 = 0,
    _pfn: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!MmPageFreeFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = MmPageFreeFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                MmPageFreeFtraceEventWire.ORDER_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._order = result.value;
                },
                MmPageFreeFtraceEventWire.PAGE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._page = result.value;
                },
                MmPageFreeFtraceEventWire.PFN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._pfn = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getOrder(self: *const MmPageFreeFtraceEventReader) u32 {
        return self._order;
    }
    pub inline fn getPage(self: *const MmPageFreeFtraceEventReader) u64 {
        return self._page;
    }
    pub inline fn getPfn(self: *const MmPageFreeFtraceEventReader) u64 {
        return self._pfn;
    }
};
const MmPageFreeBatchedFtraceEventWire = struct {
    const COLD_WIRE: gremlin.ProtoWireNumber = 1;
    const PAGE_WIRE: gremlin.ProtoWireNumber = 2;
    const PFN_WIRE: gremlin.ProtoWireNumber = 3;
};
pub const MmPageFreeBatchedFtraceEvent = struct {
    // fields
    cold: i32 = 0,
    page: u64 = 0,
    pfn: u64 = 0,
    pub fn calcProtobufSize(self: *const MmPageFreeBatchedFtraceEvent) usize {
        var res: usize = 0;
        if (self.cold != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageFreeBatchedFtraceEventWire.COLD_WIRE) + gremlin.sizes.sizeI32(self.cold);
        }
        if (self.page != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageFreeBatchedFtraceEventWire.PAGE_WIRE) + gremlin.sizes.sizeU64(self.page);
        }
        if (self.pfn != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPageFreeBatchedFtraceEventWire.PFN_WIRE) + gremlin.sizes.sizeU64(self.pfn);
        }
        return res;
    }
    pub fn encode(self: *const MmPageFreeBatchedFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const MmPageFreeBatchedFtraceEvent, target: *gremlin.Writer) void {
        if (self.cold != 0) {
            target.appendInt32(MmPageFreeBatchedFtraceEventWire.COLD_WIRE, self.cold);
        }
        if (self.page != 0) {
            target.appendUint64(MmPageFreeBatchedFtraceEventWire.PAGE_WIRE, self.page);
        }
        if (self.pfn != 0) {
            target.appendUint64(MmPageFreeBatchedFtraceEventWire.PFN_WIRE, self.pfn);
        }
    }
};
pub const MmPageFreeBatchedFtraceEventReader = struct {
    buf: gremlin.Reader,
    _cold: i32 = 0,
    _page: u64 = 0,
    _pfn: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!MmPageFreeBatchedFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = MmPageFreeBatchedFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                MmPageFreeBatchedFtraceEventWire.COLD_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._cold = result.value;
                },
                MmPageFreeBatchedFtraceEventWire.PAGE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._page = result.value;
                },
                MmPageFreeBatchedFtraceEventWire.PFN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._pfn = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getCold(self: *const MmPageFreeBatchedFtraceEventReader) i32 {
        return self._cold;
    }
    pub inline fn getPage(self: *const MmPageFreeBatchedFtraceEventReader) u64 {
        return self._page;
    }
    pub inline fn getPfn(self: *const MmPageFreeBatchedFtraceEventReader) u64 {
        return self._pfn;
    }
};
const MmPagePcpuDrainFtraceEventWire = struct {
    const MIGRATETYPE_WIRE: gremlin.ProtoWireNumber = 1;
    const ORDER_WIRE: gremlin.ProtoWireNumber = 2;
    const PAGE_WIRE: gremlin.ProtoWireNumber = 3;
    const PFN_WIRE: gremlin.ProtoWireNumber = 4;
};
pub const MmPagePcpuDrainFtraceEvent = struct {
    // fields
    migratetype: i32 = 0,
    order: u32 = 0,
    page: u64 = 0,
    pfn: u64 = 0,
    pub fn calcProtobufSize(self: *const MmPagePcpuDrainFtraceEvent) usize {
        var res: usize = 0;
        if (self.migratetype != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPagePcpuDrainFtraceEventWire.MIGRATETYPE_WIRE) + gremlin.sizes.sizeI32(self.migratetype);
        }
        if (self.order != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPagePcpuDrainFtraceEventWire.ORDER_WIRE) + gremlin.sizes.sizeU32(self.order);
        }
        if (self.page != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPagePcpuDrainFtraceEventWire.PAGE_WIRE) + gremlin.sizes.sizeU64(self.page);
        }
        if (self.pfn != 0) {
            res += gremlin.sizes.sizeWireNumber(MmPagePcpuDrainFtraceEventWire.PFN_WIRE) + gremlin.sizes.sizeU64(self.pfn);
        }
        return res;
    }
    pub fn encode(self: *const MmPagePcpuDrainFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const MmPagePcpuDrainFtraceEvent, target: *gremlin.Writer) void {
        if (self.migratetype != 0) {
            target.appendInt32(MmPagePcpuDrainFtraceEventWire.MIGRATETYPE_WIRE, self.migratetype);
        }
        if (self.order != 0) {
            target.appendUint32(MmPagePcpuDrainFtraceEventWire.ORDER_WIRE, self.order);
        }
        if (self.page != 0) {
            target.appendUint64(MmPagePcpuDrainFtraceEventWire.PAGE_WIRE, self.page);
        }
        if (self.pfn != 0) {
            target.appendUint64(MmPagePcpuDrainFtraceEventWire.PFN_WIRE, self.pfn);
        }
    }
};
pub const MmPagePcpuDrainFtraceEventReader = struct {
    buf: gremlin.Reader,
    _migratetype: i32 = 0,
    _order: u32 = 0,
    _page: u64 = 0,
    _pfn: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!MmPagePcpuDrainFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = MmPagePcpuDrainFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                MmPagePcpuDrainFtraceEventWire.MIGRATETYPE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._migratetype = result.value;
                },
                MmPagePcpuDrainFtraceEventWire.ORDER_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._order = result.value;
                },
                MmPagePcpuDrainFtraceEventWire.PAGE_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._page = result.value;
                },
                MmPagePcpuDrainFtraceEventWire.PFN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._pfn = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getMigratetype(self: *const MmPagePcpuDrainFtraceEventReader) i32 {
        return self._migratetype;
    }
    pub inline fn getOrder(self: *const MmPagePcpuDrainFtraceEventReader) u32 {
        return self._order;
    }
    pub inline fn getPage(self: *const MmPagePcpuDrainFtraceEventReader) u64 {
        return self._page;
    }
    pub inline fn getPfn(self: *const MmPagePcpuDrainFtraceEventReader) u64 {
        return self._pfn;
    }
};
const RssStatFtraceEventWire = struct {
    const MEMBER_WIRE: gremlin.ProtoWireNumber = 1;
    const SIZE_WIRE: gremlin.ProtoWireNumber = 2;
    const CURR_WIRE: gremlin.ProtoWireNumber = 3;
    const MM_ID_WIRE: gremlin.ProtoWireNumber = 4;
};
pub const RssStatFtraceEvent = struct {
    // fields
    member: i32 = 0,
    size: i64 = 0,
    curr: u32 = 0,
    mm_id: u32 = 0,
    pub fn calcProtobufSize(self: *const RssStatFtraceEvent) usize {
        var res: usize = 0;
        if (self.member != 0) {
            res += gremlin.sizes.sizeWireNumber(RssStatFtraceEventWire.MEMBER_WIRE) + gremlin.sizes.sizeI32(self.member);
        }
        if (self.size != 0) {
            res += gremlin.sizes.sizeWireNumber(RssStatFtraceEventWire.SIZE_WIRE) + gremlin.sizes.sizeI64(self.size);
        }
        if (self.curr != 0) {
            res += gremlin.sizes.sizeWireNumber(RssStatFtraceEventWire.CURR_WIRE) + gremlin.sizes.sizeU32(self.curr);
        }
        if (self.mm_id != 0) {
            res += gremlin.sizes.sizeWireNumber(RssStatFtraceEventWire.MM_ID_WIRE) + gremlin.sizes.sizeU32(self.mm_id);
        }
        return res;
    }
    pub fn encode(self: *const RssStatFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const RssStatFtraceEvent, target: *gremlin.Writer) void {
        if (self.member != 0) {
            target.appendInt32(RssStatFtraceEventWire.MEMBER_WIRE, self.member);
        }
        if (self.size != 0) {
            target.appendInt64(RssStatFtraceEventWire.SIZE_WIRE, self.size);
        }
        if (self.curr != 0) {
            target.appendUint32(RssStatFtraceEventWire.CURR_WIRE, self.curr);
        }
        if (self.mm_id != 0) {
            target.appendUint32(RssStatFtraceEventWire.MM_ID_WIRE, self.mm_id);
        }
    }
};
pub const RssStatFtraceEventReader = struct {
    buf: gremlin.Reader,
    _member: i32 = 0,
    _size: i64 = 0,
    _curr: u32 = 0,
    _mm_id: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!RssStatFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = RssStatFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                RssStatFtraceEventWire.MEMBER_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._member = result.value;
                },
                RssStatFtraceEventWire.SIZE_WIRE => {
                    const result = try buf.readInt64(offset);
                    offset += result.size;
                    res._size = result.value;
                },
                RssStatFtraceEventWire.CURR_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._curr = result.value;
                },
                RssStatFtraceEventWire.MM_ID_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._mm_id = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getMember(self: *const RssStatFtraceEventReader) i32 {
        return self._member;
    }
    pub inline fn getSize(self: *const RssStatFtraceEventReader) i64 {
        return self._size;
    }
    pub inline fn getCurr(self: *const RssStatFtraceEventReader) u32 {
        return self._curr;
    }
    pub inline fn getMmId(self: *const RssStatFtraceEventReader) u32 {
        return self._mm_id;
    }
};
const IonHeapShrinkFtraceEventWire = struct {
    const HEAP_NAME_WIRE: gremlin.ProtoWireNumber = 1;
    const LEN_WIRE: gremlin.ProtoWireNumber = 2;
    const TOTAL_ALLOCATED_WIRE: gremlin.ProtoWireNumber = 3;
};
pub const IonHeapShrinkFtraceEvent = struct {
    // fields
    heap_name: ?[]const u8 = null,
    len: u64 = 0,
    total_allocated: i64 = 0,
    pub fn calcProtobufSize(self: *const IonHeapShrinkFtraceEvent) usize {
        var res: usize = 0;
        if (self.heap_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonHeapShrinkFtraceEventWire.HEAP_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonHeapShrinkFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.total_allocated != 0) {
            res += gremlin.sizes.sizeWireNumber(IonHeapShrinkFtraceEventWire.TOTAL_ALLOCATED_WIRE) + gremlin.sizes.sizeI64(self.total_allocated);
        }
        return res;
    }
    pub fn encode(self: *const IonHeapShrinkFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonHeapShrinkFtraceEvent, target: *gremlin.Writer) void {
        if (self.heap_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonHeapShrinkFtraceEventWire.HEAP_NAME_WIRE, v);
            }
        }
        if (self.len != 0) {
            target.appendUint64(IonHeapShrinkFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.total_allocated != 0) {
            target.appendInt64(IonHeapShrinkFtraceEventWire.TOTAL_ALLOCATED_WIRE, self.total_allocated);
        }
    }
};
pub const IonHeapShrinkFtraceEventReader = struct {
    buf: gremlin.Reader,
    _heap_name: ?[]const u8 = null,
    _len: u64 = 0,
    _total_allocated: i64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonHeapShrinkFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonHeapShrinkFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonHeapShrinkFtraceEventWire.HEAP_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._heap_name = result.value;
                },
                IonHeapShrinkFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IonHeapShrinkFtraceEventWire.TOTAL_ALLOCATED_WIRE => {
                    const result = try buf.readInt64(offset);
                    offset += result.size;
                    res._total_allocated = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getHeapName(self: *const IonHeapShrinkFtraceEventReader) []const u8 {
        return self._heap_name orelse &[_]u8{};
    }
    pub inline fn getLen(self: *const IonHeapShrinkFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getTotalAllocated(self: *const IonHeapShrinkFtraceEventReader) i64 {
        return self._total_allocated;
    }
};
const IonHeapGrowFtraceEventWire = struct {
    const HEAP_NAME_WIRE: gremlin.ProtoWireNumber = 1;
    const LEN_WIRE: gremlin.ProtoWireNumber = 2;
    const TOTAL_ALLOCATED_WIRE: gremlin.ProtoWireNumber = 3;
};
pub const IonHeapGrowFtraceEvent = struct {
    // fields
    heap_name: ?[]const u8 = null,
    len: u64 = 0,
    total_allocated: i64 = 0,
    pub fn calcProtobufSize(self: *const IonHeapGrowFtraceEvent) usize {
        var res: usize = 0;
        if (self.heap_name) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(IonHeapGrowFtraceEventWire.HEAP_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonHeapGrowFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        if (self.total_allocated != 0) {
            res += gremlin.sizes.sizeWireNumber(IonHeapGrowFtraceEventWire.TOTAL_ALLOCATED_WIRE) + gremlin.sizes.sizeI64(self.total_allocated);
        }
        return res;
    }
    pub fn encode(self: *const IonHeapGrowFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonHeapGrowFtraceEvent, target: *gremlin.Writer) void {
        if (self.heap_name) |v| {
            if (v.len > 0) {
                target.appendBytes(IonHeapGrowFtraceEventWire.HEAP_NAME_WIRE, v);
            }
        }
        if (self.len != 0) {
            target.appendUint64(IonHeapGrowFtraceEventWire.LEN_WIRE, self.len);
        }
        if (self.total_allocated != 0) {
            target.appendInt64(IonHeapGrowFtraceEventWire.TOTAL_ALLOCATED_WIRE, self.total_allocated);
        }
    }
};
pub const IonHeapGrowFtraceEventReader = struct {
    buf: gremlin.Reader,
    _heap_name: ?[]const u8 = null,
    _len: u64 = 0,
    _total_allocated: i64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonHeapGrowFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonHeapGrowFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonHeapGrowFtraceEventWire.HEAP_NAME_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._heap_name = result.value;
                },
                IonHeapGrowFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                IonHeapGrowFtraceEventWire.TOTAL_ALLOCATED_WIRE => {
                    const result = try buf.readInt64(offset);
                    offset += result.size;
                    res._total_allocated = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getHeapName(self: *const IonHeapGrowFtraceEventReader) []const u8 {
        return self._heap_name orelse &[_]u8{};
    }
    pub inline fn getLen(self: *const IonHeapGrowFtraceEventReader) u64 {
        return self._len;
    }
    pub inline fn getTotalAllocated(self: *const IonHeapGrowFtraceEventReader) i64 {
        return self._total_allocated;
    }
};
const IonBufferCreateFtraceEventWire = struct {
    const ADDR_WIRE: gremlin.ProtoWireNumber = 1;
    const LEN_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const IonBufferCreateFtraceEvent = struct {
    // fields
    addr: u64 = 0,
    len: u64 = 0,
    pub fn calcProtobufSize(self: *const IonBufferCreateFtraceEvent) usize {
        var res: usize = 0;
        if (self.addr != 0) {
            res += gremlin.sizes.sizeWireNumber(IonBufferCreateFtraceEventWire.ADDR_WIRE) + gremlin.sizes.sizeU64(self.addr);
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonBufferCreateFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        return res;
    }
    pub fn encode(self: *const IonBufferCreateFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonBufferCreateFtraceEvent, target: *gremlin.Writer) void {
        if (self.addr != 0) {
            target.appendUint64(IonBufferCreateFtraceEventWire.ADDR_WIRE, self.addr);
        }
        if (self.len != 0) {
            target.appendUint64(IonBufferCreateFtraceEventWire.LEN_WIRE, self.len);
        }
    }
};
pub const IonBufferCreateFtraceEventReader = struct {
    buf: gremlin.Reader,
    _addr: u64 = 0,
    _len: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonBufferCreateFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonBufferCreateFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonBufferCreateFtraceEventWire.ADDR_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._addr = result.value;
                },
                IonBufferCreateFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getAddr(self: *const IonBufferCreateFtraceEventReader) u64 {
        return self._addr;
    }
    pub inline fn getLen(self: *const IonBufferCreateFtraceEventReader) u64 {
        return self._len;
    }
};
const IonBufferDestroyFtraceEventWire = struct {
    const ADDR_WIRE: gremlin.ProtoWireNumber = 1;
    const LEN_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const IonBufferDestroyFtraceEvent = struct {
    // fields
    addr: u64 = 0,
    len: u64 = 0,
    pub fn calcProtobufSize(self: *const IonBufferDestroyFtraceEvent) usize {
        var res: usize = 0;
        if (self.addr != 0) {
            res += gremlin.sizes.sizeWireNumber(IonBufferDestroyFtraceEventWire.ADDR_WIRE) + gremlin.sizes.sizeU64(self.addr);
        }
        if (self.len != 0) {
            res += gremlin.sizes.sizeWireNumber(IonBufferDestroyFtraceEventWire.LEN_WIRE) + gremlin.sizes.sizeU64(self.len);
        }
        return res;
    }
    pub fn encode(self: *const IonBufferDestroyFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const IonBufferDestroyFtraceEvent, target: *gremlin.Writer) void {
        if (self.addr != 0) {
            target.appendUint64(IonBufferDestroyFtraceEventWire.ADDR_WIRE, self.addr);
        }
        if (self.len != 0) {
            target.appendUint64(IonBufferDestroyFtraceEventWire.LEN_WIRE, self.len);
        }
    }
};
pub const IonBufferDestroyFtraceEventReader = struct {
    buf: gremlin.Reader,
    _addr: u64 = 0,
    _len: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!IonBufferDestroyFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = IonBufferDestroyFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                IonBufferDestroyFtraceEventWire.ADDR_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._addr = result.value;
                },
                IonBufferDestroyFtraceEventWire.LEN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._len = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getAddr(self: *const IonBufferDestroyFtraceEventReader) u64 {
        return self._addr;
    }
    pub inline fn getLen(self: *const IonBufferDestroyFtraceEventReader) u64 {
        return self._len;
    }
};
const MmAllocContigMigrateRangeInfoFtraceEventWire = struct {
    const START_WIRE: gremlin.ProtoWireNumber = 1;
    const END_WIRE: gremlin.ProtoWireNumber = 2;
    const NR_MIGRATED_WIRE: gremlin.ProtoWireNumber = 3;
    const NR_RECLAIMED_WIRE: gremlin.ProtoWireNumber = 4;
    const NR_MAPPED_WIRE: gremlin.ProtoWireNumber = 5;
    const MIGRATETYPE_WIRE: gremlin.ProtoWireNumber = 6;
};
pub const MmAllocContigMigrateRangeInfoFtraceEvent = struct {
    // fields
    start: u64 = 0,
    end: u64 = 0,
    nr_migrated: u64 = 0,
    nr_reclaimed: u64 = 0,
    nr_mapped: u64 = 0,
    migratetype: i32 = 0,
    pub fn calcProtobufSize(self: *const MmAllocContigMigrateRangeInfoFtraceEvent) usize {
        var res: usize = 0;
        if (self.start != 0) {
            res += gremlin.sizes.sizeWireNumber(MmAllocContigMigrateRangeInfoFtraceEventWire.START_WIRE) + gremlin.sizes.sizeU64(self.start);
        }
        if (self.end != 0) {
            res += gremlin.sizes.sizeWireNumber(MmAllocContigMigrateRangeInfoFtraceEventWire.END_WIRE) + gremlin.sizes.sizeU64(self.end);
        }
        if (self.nr_migrated != 0) {
            res += gremlin.sizes.sizeWireNumber(MmAllocContigMigrateRangeInfoFtraceEventWire.NR_MIGRATED_WIRE) + gremlin.sizes.sizeU64(self.nr_migrated);
        }
        if (self.nr_reclaimed != 0) {
            res += gremlin.sizes.sizeWireNumber(MmAllocContigMigrateRangeInfoFtraceEventWire.NR_RECLAIMED_WIRE) + gremlin.sizes.sizeU64(self.nr_reclaimed);
        }
        if (self.nr_mapped != 0) {
            res += gremlin.sizes.sizeWireNumber(MmAllocContigMigrateRangeInfoFtraceEventWire.NR_MAPPED_WIRE) + gremlin.sizes.sizeU64(self.nr_mapped);
        }
        if (self.migratetype != 0) {
            res += gremlin.sizes.sizeWireNumber(MmAllocContigMigrateRangeInfoFtraceEventWire.MIGRATETYPE_WIRE) + gremlin.sizes.sizeI32(self.migratetype);
        }
        return res;
    }
    pub fn encode(self: *const MmAllocContigMigrateRangeInfoFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const MmAllocContigMigrateRangeInfoFtraceEvent, target: *gremlin.Writer) void {
        if (self.start != 0) {
            target.appendUint64(MmAllocContigMigrateRangeInfoFtraceEventWire.START_WIRE, self.start);
        }
        if (self.end != 0) {
            target.appendUint64(MmAllocContigMigrateRangeInfoFtraceEventWire.END_WIRE, self.end);
        }
        if (self.nr_migrated != 0) {
            target.appendUint64(MmAllocContigMigrateRangeInfoFtraceEventWire.NR_MIGRATED_WIRE, self.nr_migrated);
        }
        if (self.nr_reclaimed != 0) {
            target.appendUint64(MmAllocContigMigrateRangeInfoFtraceEventWire.NR_RECLAIMED_WIRE, self.nr_reclaimed);
        }
        if (self.nr_mapped != 0) {
            target.appendUint64(MmAllocContigMigrateRangeInfoFtraceEventWire.NR_MAPPED_WIRE, self.nr_mapped);
        }
        if (self.migratetype != 0) {
            target.appendInt32(MmAllocContigMigrateRangeInfoFtraceEventWire.MIGRATETYPE_WIRE, self.migratetype);
        }
    }
};
pub const MmAllocContigMigrateRangeInfoFtraceEventReader = struct {
    buf: gremlin.Reader,
    _start: u64 = 0,
    _end: u64 = 0,
    _nr_migrated: u64 = 0,
    _nr_reclaimed: u64 = 0,
    _nr_mapped: u64 = 0,
    _migratetype: i32 = 0,
    pub fn init(src: []const u8) gremlin.Error!MmAllocContigMigrateRangeInfoFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = MmAllocContigMigrateRangeInfoFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                MmAllocContigMigrateRangeInfoFtraceEventWire.START_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._start = result.value;
                },
                MmAllocContigMigrateRangeInfoFtraceEventWire.END_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._end = result.value;
                },
                MmAllocContigMigrateRangeInfoFtraceEventWire.NR_MIGRATED_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._nr_migrated = result.value;
                },
                MmAllocContigMigrateRangeInfoFtraceEventWire.NR_RECLAIMED_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._nr_reclaimed = result.value;
                },
                MmAllocContigMigrateRangeInfoFtraceEventWire.NR_MAPPED_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._nr_mapped = result.value;
                },
                MmAllocContigMigrateRangeInfoFtraceEventWire.MIGRATETYPE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._migratetype = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getStart(self: *const MmAllocContigMigrateRangeInfoFtraceEventReader) u64 {
        return self._start;
    }
    pub inline fn getEnd(self: *const MmAllocContigMigrateRangeInfoFtraceEventReader) u64 {
        return self._end;
    }
    pub inline fn getNrMigrated(self: *const MmAllocContigMigrateRangeInfoFtraceEventReader) u64 {
        return self._nr_migrated;
    }
    pub inline fn getNrReclaimed(self: *const MmAllocContigMigrateRangeInfoFtraceEventReader) u64 {
        return self._nr_reclaimed;
    }
    pub inline fn getNrMapped(self: *const MmAllocContigMigrateRangeInfoFtraceEventReader) u64 {
        return self._nr_mapped;
    }
    pub inline fn getMigratetype(self: *const MmAllocContigMigrateRangeInfoFtraceEventReader) i32 {
        return self._migratetype;
    }
};
const DmabufRssStatFtraceEventWire = struct {
    const RSS_WIRE: gremlin.ProtoWireNumber = 1;
    const RSS_DELTA_WIRE: gremlin.ProtoWireNumber = 2;
    const I_INO_WIRE: gremlin.ProtoWireNumber = 3;
};
pub const DmabufRssStatFtraceEvent = struct {
    // fields
    rss: u64 = 0,
    rss_delta: i64 = 0,
    i_ino: u64 = 0,
    pub fn calcProtobufSize(self: *const DmabufRssStatFtraceEvent) usize {
        var res: usize = 0;
        if (self.rss != 0) {
            res += gremlin.sizes.sizeWireNumber(DmabufRssStatFtraceEventWire.RSS_WIRE) + gremlin.sizes.sizeU64(self.rss);
        }
        if (self.rss_delta != 0) {
            res += gremlin.sizes.sizeWireNumber(DmabufRssStatFtraceEventWire.RSS_DELTA_WIRE) + gremlin.sizes.sizeI64(self.rss_delta);
        }
        if (self.i_ino != 0) {
            res += gremlin.sizes.sizeWireNumber(DmabufRssStatFtraceEventWire.I_INO_WIRE) + gremlin.sizes.sizeU64(self.i_ino);
        }
        return res;
    }
    pub fn encode(self: *const DmabufRssStatFtraceEvent, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const DmabufRssStatFtraceEvent, target: *gremlin.Writer) void {
        if (self.rss != 0) {
            target.appendUint64(DmabufRssStatFtraceEventWire.RSS_WIRE, self.rss);
        }
        if (self.rss_delta != 0) {
            target.appendInt64(DmabufRssStatFtraceEventWire.RSS_DELTA_WIRE, self.rss_delta);
        }
        if (self.i_ino != 0) {
            target.appendUint64(DmabufRssStatFtraceEventWire.I_INO_WIRE, self.i_ino);
        }
    }
};
pub const DmabufRssStatFtraceEventReader = struct {
    buf: gremlin.Reader,
    _rss: u64 = 0,
    _rss_delta: i64 = 0,
    _i_ino: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!DmabufRssStatFtraceEventReader {
        const buf = gremlin.Reader.init(src);
        var res = DmabufRssStatFtraceEventReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                DmabufRssStatFtraceEventWire.RSS_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._rss = result.value;
                },
                DmabufRssStatFtraceEventWire.RSS_DELTA_WIRE => {
                    const result = try buf.readInt64(offset);
                    offset += result.size;
                    res._rss_delta = result.value;
                },
                DmabufRssStatFtraceEventWire.I_INO_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._i_ino = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getRss(self: *const DmabufRssStatFtraceEventReader) u64 {
        return self._rss;
    }
    pub inline fn getRssDelta(self: *const DmabufRssStatFtraceEventReader) i64 {
        return self._rss_delta;
    }
    pub inline fn getIIno(self: *const DmabufRssStatFtraceEventReader) u64 {
        return self._i_ino;
    }
};
