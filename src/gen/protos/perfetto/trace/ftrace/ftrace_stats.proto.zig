// =============================================================================
// DO NOT EDIT - This file is automatically generated by gremlin.zig
// =============================================================================
const std = @import("std");
const gremlin = @import("gremlin");
// enums
pub const FtraceParseStatus = enum(i32) {
    FTRACE_STATUS_UNSPECIFIED = 0,
    FTRACE_STATUS_OK = 1,
    FTRACE_STATUS_UNEXPECTED_READ_ERROR = 2,
    FTRACE_STATUS_PARTIAL_PAGE_READ = 3,
    FTRACE_STATUS_ABI_INVALID_PAGE_HEADER = 4,
    FTRACE_STATUS_ABI_SHORT_EVENT_HEADER = 5,
    FTRACE_STATUS_ABI_NULL_PADDING = 6,
    FTRACE_STATUS_ABI_SHORT_PADDING_LENGTH = 7,
    FTRACE_STATUS_ABI_INVALID_PADDING_LENGTH = 8,
    FTRACE_STATUS_ABI_SHORT_TIME_EXTEND = 9,
    FTRACE_STATUS_ABI_SHORT_TIME_STAMP = 10,
    FTRACE_STATUS_ABI_SHORT_DATA_LENGTH = 11,
    FTRACE_STATUS_ABI_ZERO_DATA_LENGTH = 12,
    FTRACE_STATUS_ABI_INVALID_DATA_LENGTH = 13,
    FTRACE_STATUS_ABI_SHORT_EVENT_ID = 14,
    FTRACE_STATUS_ABI_END_OVERFLOW = 15,
    FTRACE_STATUS_SHORT_COMPACT_EVENT = 16,
    FTRACE_STATUS_INVALID_EVENT = 17,
};
// structs
const FtraceCpuStatsWire = struct {
    const CPU_WIRE: gremlin.ProtoWireNumber = 1;
    const ENTRIES_WIRE: gremlin.ProtoWireNumber = 2;
    const OVERRUN_WIRE: gremlin.ProtoWireNumber = 3;
    const COMMIT_OVERRUN_WIRE: gremlin.ProtoWireNumber = 4;
    const BYTES_READ_WIRE: gremlin.ProtoWireNumber = 5;
    const OLDEST_EVENT_TS_WIRE: gremlin.ProtoWireNumber = 6;
    const NOW_TS_WIRE: gremlin.ProtoWireNumber = 7;
    const DROPPED_EVENTS_WIRE: gremlin.ProtoWireNumber = 8;
    const READ_EVENTS_WIRE: gremlin.ProtoWireNumber = 9;
};
pub const FtraceCpuStats = struct {
    // fields
    cpu: u64 = 0,
    entries: u64 = 0,
    overrun: u64 = 0,
    commit_overrun: u64 = 0,
    bytes_read: u64 = 0,
    oldest_event_ts: f64 = 0.0,
    now_ts: f64 = 0.0,
    dropped_events: u64 = 0,
    read_events: u64 = 0,
    pub fn calcProtobufSize(self: *const FtraceCpuStats) usize {
        var res: usize = 0;
        if (self.cpu != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceCpuStatsWire.CPU_WIRE) + gremlin.sizes.sizeU64(self.cpu);
        }
        if (self.entries != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceCpuStatsWire.ENTRIES_WIRE) + gremlin.sizes.sizeU64(self.entries);
        }
        if (self.overrun != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceCpuStatsWire.OVERRUN_WIRE) + gremlin.sizes.sizeU64(self.overrun);
        }
        if (self.commit_overrun != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceCpuStatsWire.COMMIT_OVERRUN_WIRE) + gremlin.sizes.sizeU64(self.commit_overrun);
        }
        if (self.bytes_read != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceCpuStatsWire.BYTES_READ_WIRE) + gremlin.sizes.sizeU64(self.bytes_read);
        }
        if (self.oldest_event_ts != 0.0) {
            res += gremlin.sizes.sizeWireNumber(FtraceCpuStatsWire.OLDEST_EVENT_TS_WIRE) + gremlin.sizes.sizeDouble(self.oldest_event_ts);
        }
        if (self.now_ts != 0.0) {
            res += gremlin.sizes.sizeWireNumber(FtraceCpuStatsWire.NOW_TS_WIRE) + gremlin.sizes.sizeDouble(self.now_ts);
        }
        if (self.dropped_events != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceCpuStatsWire.DROPPED_EVENTS_WIRE) + gremlin.sizes.sizeU64(self.dropped_events);
        }
        if (self.read_events != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceCpuStatsWire.READ_EVENTS_WIRE) + gremlin.sizes.sizeU64(self.read_events);
        }
        return res;
    }
    pub fn encode(self: *const FtraceCpuStats, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const FtraceCpuStats, target: *gremlin.Writer) void {
        if (self.cpu != 0) {
            target.appendUint64(FtraceCpuStatsWire.CPU_WIRE, self.cpu);
        }
        if (self.entries != 0) {
            target.appendUint64(FtraceCpuStatsWire.ENTRIES_WIRE, self.entries);
        }
        if (self.overrun != 0) {
            target.appendUint64(FtraceCpuStatsWire.OVERRUN_WIRE, self.overrun);
        }
        if (self.commit_overrun != 0) {
            target.appendUint64(FtraceCpuStatsWire.COMMIT_OVERRUN_WIRE, self.commit_overrun);
        }
        if (self.bytes_read != 0) {
            target.appendUint64(FtraceCpuStatsWire.BYTES_READ_WIRE, self.bytes_read);
        }
        if (self.oldest_event_ts != 0.0) {
            target.appendFloat64(FtraceCpuStatsWire.OLDEST_EVENT_TS_WIRE, self.oldest_event_ts);
        }
        if (self.now_ts != 0.0) {
            target.appendFloat64(FtraceCpuStatsWire.NOW_TS_WIRE, self.now_ts);
        }
        if (self.dropped_events != 0) {
            target.appendUint64(FtraceCpuStatsWire.DROPPED_EVENTS_WIRE, self.dropped_events);
        }
        if (self.read_events != 0) {
            target.appendUint64(FtraceCpuStatsWire.READ_EVENTS_WIRE, self.read_events);
        }
    }
};
pub const FtraceCpuStatsReader = struct {
    buf: gremlin.Reader,
    _cpu: u64 = 0,
    _entries: u64 = 0,
    _overrun: u64 = 0,
    _commit_overrun: u64 = 0,
    _bytes_read: u64 = 0,
    _oldest_event_ts: f64 = 0.0,
    _now_ts: f64 = 0.0,
    _dropped_events: u64 = 0,
    _read_events: u64 = 0,
    pub fn init(src: []const u8) gremlin.Error!FtraceCpuStatsReader {
        const buf = gremlin.Reader.init(src);
        var res = FtraceCpuStatsReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                FtraceCpuStatsWire.CPU_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._cpu = result.value;
                },
                FtraceCpuStatsWire.ENTRIES_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._entries = result.value;
                },
                FtraceCpuStatsWire.OVERRUN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._overrun = result.value;
                },
                FtraceCpuStatsWire.COMMIT_OVERRUN_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._commit_overrun = result.value;
                },
                FtraceCpuStatsWire.BYTES_READ_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._bytes_read = result.value;
                },
                FtraceCpuStatsWire.OLDEST_EVENT_TS_WIRE => {
                    const result = try buf.readFloat64(offset);
                    offset += result.size;
                    res._oldest_event_ts = result.value;
                },
                FtraceCpuStatsWire.NOW_TS_WIRE => {
                    const result = try buf.readFloat64(offset);
                    offset += result.size;
                    res._now_ts = result.value;
                },
                FtraceCpuStatsWire.DROPPED_EVENTS_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._dropped_events = result.value;
                },
                FtraceCpuStatsWire.READ_EVENTS_WIRE => {
                    const result = try buf.readUInt64(offset);
                    offset += result.size;
                    res._read_events = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getCpu(self: *const FtraceCpuStatsReader) u64 {
        return self._cpu;
    }
    pub inline fn getEntries(self: *const FtraceCpuStatsReader) u64 {
        return self._entries;
    }
    pub inline fn getOverrun(self: *const FtraceCpuStatsReader) u64 {
        return self._overrun;
    }
    pub inline fn getCommitOverrun(self: *const FtraceCpuStatsReader) u64 {
        return self._commit_overrun;
    }
    pub inline fn getBytesRead(self: *const FtraceCpuStatsReader) u64 {
        return self._bytes_read;
    }
    pub inline fn getOldestEventTs(self: *const FtraceCpuStatsReader) f64 {
        return self._oldest_event_ts;
    }
    pub inline fn getNowTs(self: *const FtraceCpuStatsReader) f64 {
        return self._now_ts;
    }
    pub inline fn getDroppedEvents(self: *const FtraceCpuStatsReader) u64 {
        return self._dropped_events;
    }
    pub inline fn getReadEvents(self: *const FtraceCpuStatsReader) u64 {
        return self._read_events;
    }
};
const FtraceKprobeStatsWire = struct {
    const HITS_WIRE: gremlin.ProtoWireNumber = 1;
    const MISSES_WIRE: gremlin.ProtoWireNumber = 2;
};
pub const FtraceKprobeStats = struct {
    // fields
    hits: i64 = 0,
    misses: i64 = 0,
    pub fn calcProtobufSize(self: *const FtraceKprobeStats) usize {
        var res: usize = 0;
        if (self.hits != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceKprobeStatsWire.HITS_WIRE) + gremlin.sizes.sizeI64(self.hits);
        }
        if (self.misses != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceKprobeStatsWire.MISSES_WIRE) + gremlin.sizes.sizeI64(self.misses);
        }
        return res;
    }
    pub fn encode(self: *const FtraceKprobeStats, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const FtraceKprobeStats, target: *gremlin.Writer) void {
        if (self.hits != 0) {
            target.appendInt64(FtraceKprobeStatsWire.HITS_WIRE, self.hits);
        }
        if (self.misses != 0) {
            target.appendInt64(FtraceKprobeStatsWire.MISSES_WIRE, self.misses);
        }
    }
};
pub const FtraceKprobeStatsReader = struct {
    buf: gremlin.Reader,
    _hits: i64 = 0,
    _misses: i64 = 0,
    pub fn init(src: []const u8) gremlin.Error!FtraceKprobeStatsReader {
        const buf = gremlin.Reader.init(src);
        var res = FtraceKprobeStatsReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                FtraceKprobeStatsWire.HITS_WIRE => {
                    const result = try buf.readInt64(offset);
                    offset += result.size;
                    res._hits = result.value;
                },
                FtraceKprobeStatsWire.MISSES_WIRE => {
                    const result = try buf.readInt64(offset);
                    offset += result.size;
                    res._misses = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getHits(self: *const FtraceKprobeStatsReader) i64 {
        return self._hits;
    }
    pub inline fn getMisses(self: *const FtraceKprobeStatsReader) i64 {
        return self._misses;
    }
};
const FtraceStatsWire = struct {
    const PHASE_WIRE: gremlin.ProtoWireNumber = 1;
    const CPU_STATS_WIRE: gremlin.ProtoWireNumber = 2;
    const KERNEL_SYMBOLS_PARSED_WIRE: gremlin.ProtoWireNumber = 3;
    const KERNEL_SYMBOLS_MEM_KB_WIRE: gremlin.ProtoWireNumber = 4;
    const ATRACE_ERRORS_WIRE: gremlin.ProtoWireNumber = 5;
    const EXCLUSIVE_FEATURE_ERROR_WIRE: gremlin.ProtoWireNumber = 13;
    const UNKNOWN_FTRACE_EVENTS_WIRE: gremlin.ProtoWireNumber = 6;
    const FAILED_FTRACE_EVENTS_WIRE: gremlin.ProtoWireNumber = 7;
    const PRESERVE_FTRACE_BUFFER_WIRE: gremlin.ProtoWireNumber = 8;
    const FTRACE_PARSE_ERRORS_WIRE: gremlin.ProtoWireNumber = 9;
    const KPROBE_STATS_WIRE: gremlin.ProtoWireNumber = 10;
    const CPU_BUFFER_SIZE_PAGES_WIRE: gremlin.ProtoWireNumber = 11;
    const CACHED_CPU_BUFFER_SIZE_PAGES_WIRE: gremlin.ProtoWireNumber = 12;
};
pub const FtraceStats = struct {
    // nested enums
    pub const Phase = enum(i32) {
        UNSPECIFIED = 0,
        START_OF_TRACE = 1,
        END_OF_TRACE = 2,
    };
    // fields
    phase: FtraceStats.Phase = @enumFromInt(0),
    cpu_stats: ?[]const ?FtraceCpuStats = null,
    kernel_symbols_parsed: u32 = 0,
    kernel_symbols_mem_kb: u32 = 0,
    atrace_errors: ?[]const u8 = null,
    exclusive_feature_error: ?[]const u8 = null,
    unknown_ftrace_events: ?[]const ?[]const u8 = null,
    failed_ftrace_events: ?[]const ?[]const u8 = null,
    preserve_ftrace_buffer: bool = false,
    ftrace_parse_errors: ?[]const FtraceParseStatus = null,
    kprobe_stats: ?FtraceKprobeStats = null,
    cpu_buffer_size_pages: u32 = 0,
    cached_cpu_buffer_size_pages: u32 = 0,
    pub fn calcProtobufSize(self: *const FtraceStats) usize {
        var res: usize = 0;
        if (@intFromEnum(self.phase) != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.PHASE_WIRE) + gremlin.sizes.sizeI32(@intFromEnum(self.phase));
        }
        if (self.cpu_stats) |arr| {
            for (arr) |maybe_v| {
                res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.CPU_STATS_WIRE);
                if (maybe_v) |v| {
                    const size = v.calcProtobufSize();
                    res += gremlin.sizes.sizeUsize(size) + size;
                } else {
                    res += gremlin.sizes.sizeUsize(0);
                }
            }
        }
        if (self.kernel_symbols_parsed != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.KERNEL_SYMBOLS_PARSED_WIRE) + gremlin.sizes.sizeU32(self.kernel_symbols_parsed);
        }
        if (self.kernel_symbols_mem_kb != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.KERNEL_SYMBOLS_MEM_KB_WIRE) + gremlin.sizes.sizeU32(self.kernel_symbols_mem_kb);
        }
        if (self.atrace_errors) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.ATRACE_ERRORS_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.exclusive_feature_error) |v| {
            if (v.len > 0) {
                res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.EXCLUSIVE_FEATURE_ERROR_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
            }
        }
        if (self.unknown_ftrace_events) |arr| {
            for (arr) |maybe_v| {
                res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.UNKNOWN_FTRACE_EVENTS_WIRE);
                if (maybe_v) |v| {
                    res += gremlin.sizes.sizeUsize(v.len) + v.len;
                } else {
                    res += gremlin.sizes.sizeUsize(0);
                }
            }
        }
        if (self.failed_ftrace_events) |arr| {
            for (arr) |maybe_v| {
                res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.FAILED_FTRACE_EVENTS_WIRE);
                if (maybe_v) |v| {
                    res += gremlin.sizes.sizeUsize(v.len) + v.len;
                } else {
                    res += gremlin.sizes.sizeUsize(0);
                }
            }
        }
        if (self.preserve_ftrace_buffer != false) {
            res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.PRESERVE_FTRACE_BUFFER_WIRE) + gremlin.sizes.sizeBool(self.preserve_ftrace_buffer);
        }
        if (self.ftrace_parse_errors) |arr| {
            if (arr.len == 0) {} else if (arr.len == 1) {
                res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.FTRACE_PARSE_ERRORS_WIRE) + gremlin.sizes.sizeI32(@intFromEnum(arr[0]));
            } else {
                var packed_size: usize = 0;
                for (arr) |v| {
                    packed_size += gremlin.sizes.sizeI32(@intFromEnum(v));
                }
                res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.FTRACE_PARSE_ERRORS_WIRE) + gremlin.sizes.sizeUsize(packed_size) + packed_size;
            }
        }
        if (self.kprobe_stats) |v| {
            const size = v.calcProtobufSize();
            if (size > 0) {
                res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.KPROBE_STATS_WIRE) + gremlin.sizes.sizeUsize(size) + size;
            }
        }
        if (self.cpu_buffer_size_pages != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.CPU_BUFFER_SIZE_PAGES_WIRE) + gremlin.sizes.sizeU32(self.cpu_buffer_size_pages);
        }
        if (self.cached_cpu_buffer_size_pages != 0) {
            res += gremlin.sizes.sizeWireNumber(FtraceStatsWire.CACHED_CPU_BUFFER_SIZE_PAGES_WIRE) + gremlin.sizes.sizeU32(self.cached_cpu_buffer_size_pages);
        }
        return res;
    }
    pub fn encode(self: *const FtraceStats, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const FtraceStats, target: *gremlin.Writer) void {
        if (@intFromEnum(self.phase) != 0) {
            target.appendInt32(FtraceStatsWire.PHASE_WIRE, @intFromEnum(self.phase));
        }
        if (self.cpu_stats) |arr| {
            for (arr) |maybe_v| {
                if (maybe_v) |v| {
                    const size = v.calcProtobufSize();
                    target.appendBytesTag(FtraceStatsWire.CPU_STATS_WIRE, size);
                    v.encodeTo(target);
                } else {
                    target.appendBytesTag(FtraceStatsWire.CPU_STATS_WIRE, 0);
                }
            }
        }
        if (self.kernel_symbols_parsed != 0) {
            target.appendUint32(FtraceStatsWire.KERNEL_SYMBOLS_PARSED_WIRE, self.kernel_symbols_parsed);
        }
        if (self.kernel_symbols_mem_kb != 0) {
            target.appendUint32(FtraceStatsWire.KERNEL_SYMBOLS_MEM_KB_WIRE, self.kernel_symbols_mem_kb);
        }
        if (self.atrace_errors) |v| {
            if (v.len > 0) {
                target.appendBytes(FtraceStatsWire.ATRACE_ERRORS_WIRE, v);
            }
        }
        if (self.exclusive_feature_error) |v| {
            if (v.len > 0) {
                target.appendBytes(FtraceStatsWire.EXCLUSIVE_FEATURE_ERROR_WIRE, v);
            }
        }
        if (self.unknown_ftrace_events) |arr| {
            for (arr) |maybe_v| {
                if (maybe_v) |v| {
                    target.appendBytes(FtraceStatsWire.UNKNOWN_FTRACE_EVENTS_WIRE, v);
                } else {
                    target.appendBytesTag(FtraceStatsWire.UNKNOWN_FTRACE_EVENTS_WIRE, 0);
                }
            }
        }
        if (self.failed_ftrace_events) |arr| {
            for (arr) |maybe_v| {
                if (maybe_v) |v| {
                    target.appendBytes(FtraceStatsWire.FAILED_FTRACE_EVENTS_WIRE, v);
                } else {
                    target.appendBytesTag(FtraceStatsWire.FAILED_FTRACE_EVENTS_WIRE, 0);
                }
            }
        }
        if (self.preserve_ftrace_buffer != false) {
            target.appendBool(FtraceStatsWire.PRESERVE_FTRACE_BUFFER_WIRE, self.preserve_ftrace_buffer);
        }
        if (self.ftrace_parse_errors) |arr| {
            if (arr.len == 0) {} else if (arr.len == 1) {
                target.appendInt32(FtraceStatsWire.FTRACE_PARSE_ERRORS_WIRE, @intFromEnum(arr[0]));
            } else {
                var packed_size: usize = 0;
                for (arr) |v| {
                    packed_size += gremlin.sizes.sizeI32(@intFromEnum(v));
                }
                target.appendBytesTag(FtraceStatsWire.FTRACE_PARSE_ERRORS_WIRE, packed_size);
                for (arr) |v| {
                    target.appendInt32WithoutTag(@intFromEnum(v));
                }
            }
        }
        if (self.kprobe_stats) |v| {
            const size = v.calcProtobufSize();
            if (size > 0) {
                target.appendBytesTag(FtraceStatsWire.KPROBE_STATS_WIRE, size);
                v.encodeTo(target);
            }
        }
        if (self.cpu_buffer_size_pages != 0) {
            target.appendUint32(FtraceStatsWire.CPU_BUFFER_SIZE_PAGES_WIRE, self.cpu_buffer_size_pages);
        }
        if (self.cached_cpu_buffer_size_pages != 0) {
            target.appendUint32(FtraceStatsWire.CACHED_CPU_BUFFER_SIZE_PAGES_WIRE, self.cached_cpu_buffer_size_pages);
        }
    }
};
pub const FtraceStatsReader = struct {
    buf: gremlin.Reader,
    _phase: FtraceStats.Phase = @enumFromInt(0),
    _cpu_stats_offset: ?usize = null,
    _cpu_stats_last_offset: ?usize = null,
    _cpu_stats_cnt: usize = 0,
    _kernel_symbols_parsed: u32 = 0,
    _kernel_symbols_mem_kb: u32 = 0,
    _atrace_errors: ?[]const u8 = null,
    _exclusive_feature_error: ?[]const u8 = null,
    _unknown_ftrace_events_offset: ?usize = null,
    _unknown_ftrace_events_last_offset: ?usize = null,
    _unknown_ftrace_events_cnt: usize = 0,
    _failed_ftrace_events_offset: ?usize = null,
    _failed_ftrace_events_last_offset: ?usize = null,
    _failed_ftrace_events_cnt: usize = 0,
    _preserve_ftrace_buffer: bool = false,
    _ftrace_parse_errors_offset: ?usize = null,
    _ftrace_parse_errors_last_offset: ?usize = null,
    _ftrace_parse_errors_packed: bool = false,
    _kprobe_stats_buf: ?[]const u8 = null,
    _cpu_buffer_size_pages: u32 = 0,
    _cached_cpu_buffer_size_pages: u32 = 0,
    pub fn init(src: []const u8) gremlin.Error!FtraceStatsReader {
        const buf = gremlin.Reader.init(src);
        var res = FtraceStatsReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                FtraceStatsWire.PHASE_WIRE => {
                    const result = try buf.readInt32(offset);
                    offset += result.size;
                    res._phase = @enumFromInt(result.value);
                },
                FtraceStatsWire.CPU_STATS_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    if (res._cpu_stats_offset == null) {
                        res._cpu_stats_offset = offset - result.size;
                    }
                    res._cpu_stats_last_offset = offset;
                    res._cpu_stats_cnt += 1;
                },
                FtraceStatsWire.KERNEL_SYMBOLS_PARSED_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._kernel_symbols_parsed = result.value;
                },
                FtraceStatsWire.KERNEL_SYMBOLS_MEM_KB_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._kernel_symbols_mem_kb = result.value;
                },
                FtraceStatsWire.ATRACE_ERRORS_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._atrace_errors = result.value;
                },
                FtraceStatsWire.EXCLUSIVE_FEATURE_ERROR_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._exclusive_feature_error = result.value;
                },
                FtraceStatsWire.UNKNOWN_FTRACE_EVENTS_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    if (res._unknown_ftrace_events_offset == null) {
                        res._unknown_ftrace_events_offset = offset - result.size;
                    }
                    res._unknown_ftrace_events_last_offset = offset;
                    res._unknown_ftrace_events_cnt += 1;
                },
                FtraceStatsWire.FAILED_FTRACE_EVENTS_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    if (res._failed_ftrace_events_offset == null) {
                        res._failed_ftrace_events_offset = offset - result.size;
                    }
                    res._failed_ftrace_events_last_offset = offset;
                    res._failed_ftrace_events_cnt += 1;
                },
                FtraceStatsWire.PRESERVE_FTRACE_BUFFER_WIRE => {
                    const result = try buf.readBool(offset);
                    offset += result.size;
                    res._preserve_ftrace_buffer = result.value;
                },
                FtraceStatsWire.FTRACE_PARSE_ERRORS_WIRE => {
                    if (res._ftrace_parse_errors_offset == null) {
                        res._ftrace_parse_errors_offset = offset;
                    }
                    if (tag.wire == gremlin.ProtoWireType.bytes) {
                        res._ftrace_parse_errors_packed = true;
                        const length_result = try buf.readVarInt(offset);
                        res._ftrace_parse_errors_offset = offset + length_result.size;
                        res._ftrace_parse_errors_last_offset = offset + length_result.size + @as(usize, @intCast(length_result.value));
                        offset = res._ftrace_parse_errors_last_offset.?;
                    } else {
                        const result = try buf.readInt32(offset);
                        offset += result.size;
                        res._ftrace_parse_errors_last_offset = offset;
                    }
                },
                FtraceStatsWire.KPROBE_STATS_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    res._kprobe_stats_buf = result.value;
                },
                FtraceStatsWire.CPU_BUFFER_SIZE_PAGES_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._cpu_buffer_size_pages = result.value;
                },
                FtraceStatsWire.CACHED_CPU_BUFFER_SIZE_PAGES_WIRE => {
                    const result = try buf.readUInt32(offset);
                    offset += result.size;
                    res._cached_cpu_buffer_size_pages = result.value;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub inline fn getPhase(self: *const FtraceStatsReader) FtraceStats.Phase {
        return self._phase;
    }
    pub fn cpuStatsCount(self: *const FtraceStatsReader) usize {
        return self._cpu_stats_cnt;
    }
    pub fn cpuStatsNext(self: *FtraceStatsReader) ?FtraceCpuStatsReader {
        if (self._cpu_stats_offset == null) return null;
        const current_offset = self._cpu_stats_offset.?;
        const result = self.buf.readBytes(current_offset) catch return null;
        const msg = FtraceCpuStatsReader.init(result.value) catch return null;
        if (self._cpu_stats_last_offset != null and current_offset >= self._cpu_stats_last_offset.?) {
            self._cpu_stats_offset = null;
            return msg;
        }
        if (self._cpu_stats_last_offset == null) unreachable;
        var next_offset = current_offset + result.size;
        const max_offset = self._cpu_stats_last_offset.?;
        while (next_offset <= max_offset and self.buf.hasNext(next_offset, 0)) {
            const tag = self.buf.readTagAt(next_offset) catch break;
            next_offset += tag.size;
            if (tag.number == FtraceStatsWire.CPU_STATS_WIRE) {
                self._cpu_stats_offset = next_offset;
                return msg;
            } else {
                next_offset = self.buf.skipData(next_offset, tag.wire) catch break;
            }
        }
        self._cpu_stats_offset = null;
        return msg;
    }
    pub inline fn getKernelSymbolsParsed(self: *const FtraceStatsReader) u32 {
        return self._kernel_symbols_parsed;
    }
    pub inline fn getKernelSymbolsMemKb(self: *const FtraceStatsReader) u32 {
        return self._kernel_symbols_mem_kb;
    }
    pub inline fn getAtraceErrors(self: *const FtraceStatsReader) []const u8 {
        return self._atrace_errors orelse &[_]u8{};
    }
    pub inline fn getExclusiveFeatureError(self: *const FtraceStatsReader) []const u8 {
        return self._exclusive_feature_error orelse &[_]u8{};
    }
    pub fn unknownFtraceEventsCount(self: *const FtraceStatsReader) usize {
        return self._unknown_ftrace_events_cnt;
    }
    pub fn unknownFtraceEventsNext(self: *FtraceStatsReader) ?[]const u8 {
        if (self._unknown_ftrace_events_offset == null) return null;
        const current_offset = self._unknown_ftrace_events_offset.?;
        const result = self.buf.readBytes(current_offset) catch return null;
        if (self._unknown_ftrace_events_last_offset != null and current_offset >= self._unknown_ftrace_events_last_offset.?) {
            self._unknown_ftrace_events_offset = null;
            return result.value;
        }
        if (self._unknown_ftrace_events_last_offset == null) unreachable;
        var next_offset = current_offset + result.size;
        const max_offset = self._unknown_ftrace_events_last_offset.?;
        while (next_offset <= max_offset and self.buf.hasNext(next_offset, 0)) {
            const tag = self.buf.readTagAt(next_offset) catch break;
            next_offset += tag.size;
            if (tag.number == FtraceStatsWire.UNKNOWN_FTRACE_EVENTS_WIRE) {
                self._unknown_ftrace_events_offset = next_offset;
                return result.value;
            } else {
                next_offset = self.buf.skipData(next_offset, tag.wire) catch break;
            }
        }
        self._unknown_ftrace_events_offset = null;
        return result.value;
    }
    pub fn failedFtraceEventsCount(self: *const FtraceStatsReader) usize {
        return self._failed_ftrace_events_cnt;
    }
    pub fn failedFtraceEventsNext(self: *FtraceStatsReader) ?[]const u8 {
        if (self._failed_ftrace_events_offset == null) return null;
        const current_offset = self._failed_ftrace_events_offset.?;
        const result = self.buf.readBytes(current_offset) catch return null;
        if (self._failed_ftrace_events_last_offset != null and current_offset >= self._failed_ftrace_events_last_offset.?) {
            self._failed_ftrace_events_offset = null;
            return result.value;
        }
        if (self._failed_ftrace_events_last_offset == null) unreachable;
        var next_offset = current_offset + result.size;
        const max_offset = self._failed_ftrace_events_last_offset.?;
        while (next_offset <= max_offset and self.buf.hasNext(next_offset, 0)) {
            const tag = self.buf.readTagAt(next_offset) catch break;
            next_offset += tag.size;
            if (tag.number == FtraceStatsWire.FAILED_FTRACE_EVENTS_WIRE) {
                self._failed_ftrace_events_offset = next_offset;
                return result.value;
            } else {
                next_offset = self.buf.skipData(next_offset, tag.wire) catch break;
            }
        }
        self._failed_ftrace_events_offset = null;
        return result.value;
    }
    pub inline fn getPreserveFtraceBuffer(self: *const FtraceStatsReader) bool {
        return self._preserve_ftrace_buffer;
    }
    pub fn ftraceParseErrorsNext(self: *FtraceStatsReader) gremlin.Error!?FtraceParseStatus {
        if (self._ftrace_parse_errors_offset == null) return null;
        const current_offset = self._ftrace_parse_errors_offset.?;
        if (current_offset >= self._ftrace_parse_errors_last_offset.?) {
            self._ftrace_parse_errors_offset = null;
            return null;
        }
        if (self._ftrace_parse_errors_packed) {
            const value_result = try self.buf.readInt32(current_offset);
            self._ftrace_parse_errors_offset = current_offset + value_result.size;
            if (self._ftrace_parse_errors_offset.? >= self._ftrace_parse_errors_last_offset.?) {
                self._ftrace_parse_errors_offset = null;
            }
            return @enumFromInt(value_result.value);
        } else {
            const value_result = try self.buf.readInt32(current_offset);
            var next_offset = current_offset + value_result.size;
            const max_offset = self._ftrace_parse_errors_last_offset.?;
            // Search for the next occurrence of this field
            while (next_offset < max_offset and self.buf.hasNext(next_offset, 0)) {
                const next_tag = try self.buf.readTagAt(next_offset);
                next_offset += next_tag.size;
                if (next_tag.number == FtraceStatsWire.FTRACE_PARSE_ERRORS_WIRE) {
                    self._ftrace_parse_errors_offset = next_offset;
                    return @enumFromInt(value_result.value);
                } else {
                    next_offset = try self.buf.skipData(next_offset, next_tag.wire);
                }
            }
            self._ftrace_parse_errors_offset = null;
            return @enumFromInt(value_result.value);
        }
    }
    pub fn getKprobeStats(self: *const FtraceStatsReader) gremlin.Error!FtraceKprobeStatsReader {
        if (self._kprobe_stats_buf) |buf| {
            return try FtraceKprobeStatsReader.init(buf);
        }
        return try FtraceKprobeStatsReader.init(&[_]u8{});
    }
    pub inline fn getCpuBufferSizePages(self: *const FtraceStatsReader) u32 {
        return self._cpu_buffer_size_pages;
    }
    pub inline fn getCachedCpuBufferSizePages(self: *const FtraceStatsReader) u32 {
        return self._cached_cpu_buffer_size_pages;
    }
};
