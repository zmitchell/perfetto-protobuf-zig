// =============================================================================
// DO NOT EDIT - This file is automatically generated by gremlin.zig
// =============================================================================
const std = @import("std");
const gremlin = @import("gremlin");
const process_metadata = @import("process_metadata.proto.zig");
// structs
const JavaHeapStatsWire = struct {
    const INSTANCE_STATS_WIRE: gremlin.ProtoWireNumber = 1;
};
pub const JavaHeapStats = struct {
    // nested structs
    const HeapRootsWire = struct {
        const ROOT_TYPE_WIRE: gremlin.ProtoWireNumber = 1;
        const TYPE_NAME_WIRE: gremlin.ProtoWireNumber = 2;
        const OBJ_COUNT_WIRE: gremlin.ProtoWireNumber = 3;
    };
    pub const HeapRoots = struct {
        // fields
        root_type: ?[]const u8 = null,
        type_name: ?[]const u8 = null,
        obj_count: i64 = 0,
        pub fn calcProtobufSize(self: *const JavaHeapStats.HeapRoots) usize {
            var res: usize = 0;
            if (self.root_type) |v| {
                if (v.len > 0) {
                    res += gremlin.sizes.sizeWireNumber(JavaHeapStats.HeapRootsWire.ROOT_TYPE_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
                }
            }
            if (self.type_name) |v| {
                if (v.len > 0) {
                    res += gremlin.sizes.sizeWireNumber(JavaHeapStats.HeapRootsWire.TYPE_NAME_WIRE) + gremlin.sizes.sizeUsize(v.len) + v.len;
                }
            }
            if (self.obj_count != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.HeapRootsWire.OBJ_COUNT_WIRE) + gremlin.sizes.sizeI64(self.obj_count);
            }
            return res;
        }
        pub fn encode(self: *const JavaHeapStats.HeapRoots, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
            const size = self.calcProtobufSize();
            if (size == 0) {
                return &[_]u8{};
            }
            const buf = try allocator.alloc(u8, self.calcProtobufSize());
            var writer = gremlin.Writer.init(buf);
            self.encodeTo(&writer);
            return buf;
        }
        pub fn encodeTo(self: *const JavaHeapStats.HeapRoots, target: *gremlin.Writer) void {
            if (self.root_type) |v| {
                if (v.len > 0) {
                    target.appendBytes(JavaHeapStats.HeapRootsWire.ROOT_TYPE_WIRE, v);
                }
            }
            if (self.type_name) |v| {
                if (v.len > 0) {
                    target.appendBytes(JavaHeapStats.HeapRootsWire.TYPE_NAME_WIRE, v);
                }
            }
            if (self.obj_count != 0) {
                target.appendInt64(JavaHeapStats.HeapRootsWire.OBJ_COUNT_WIRE, self.obj_count);
            }
        }
    };
    pub const HeapRootsReader = struct {
        buf: gremlin.Reader,
        _root_type: ?[]const u8 = null,
        _type_name: ?[]const u8 = null,
        _obj_count: i64 = 0,
        pub fn init(src: []const u8) gremlin.Error!JavaHeapStats.HeapRootsReader {
            const buf = gremlin.Reader.init(src);
            var res = JavaHeapStats.HeapRootsReader{ .buf = buf };
            if (buf.buf.len == 0) {
                return res;
            }
            var offset: usize = 0;
            while (buf.hasNext(offset, 0)) {
                const tag = try buf.readTagAt(offset);
                offset += tag.size;
                switch (tag.number) {
                    JavaHeapStats.HeapRootsWire.ROOT_TYPE_WIRE => {
                        const result = try buf.readBytes(offset);
                        offset += result.size;
                        res._root_type = result.value;
                    },
                    JavaHeapStats.HeapRootsWire.TYPE_NAME_WIRE => {
                        const result = try buf.readBytes(offset);
                        offset += result.size;
                        res._type_name = result.value;
                    },
                    JavaHeapStats.HeapRootsWire.OBJ_COUNT_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._obj_count = result.value;
                    },
                    else => {
                        offset = try buf.skipData(offset, tag.wire);
                    },
                }
            }
            return res;
        }
        pub fn sourceBytes(self: *const @This()) []const u8 {
            return self.buf.buf;
        }
        pub inline fn getRootType(self: *const JavaHeapStats.HeapRootsReader) []const u8 {
            return self._root_type orelse &[_]u8{};
        }
        pub inline fn getTypeName(self: *const JavaHeapStats.HeapRootsReader) []const u8 {
            return self._type_name orelse &[_]u8{};
        }
        pub inline fn getObjCount(self: *const JavaHeapStats.HeapRootsReader) i64 {
            return self._obj_count;
        }
    };
    const SampleWire = struct {
        const TS_WIRE: gremlin.ProtoWireNumber = 1;
        const HEAP_SIZE_WIRE: gremlin.ProtoWireNumber = 2;
        const HEAP_NATIVE_SIZE_WIRE: gremlin.ProtoWireNumber = 8;
        const OBJ_COUNT_WIRE: gremlin.ProtoWireNumber = 4;
        const REACHABLE_HEAP_SIZE_WIRE: gremlin.ProtoWireNumber = 3;
        const REACHABLE_HEAP_NATIVE_SIZE_WIRE: gremlin.ProtoWireNumber = 9;
        const REACHABLE_OBJ_COUNT_WIRE: gremlin.ProtoWireNumber = 5;
        const ANON_RSS_AND_SWAP_SIZE_WIRE: gremlin.ProtoWireNumber = 6;
        const ROOTS_WIRE: gremlin.ProtoWireNumber = 7;
        const OOM_SCORE_ADJ_WIRE: gremlin.ProtoWireNumber = 10;
        const PROCESS_UPTIME_MS_WIRE: gremlin.ProtoWireNumber = 11;
    };
    pub const Sample = struct {
        // fields
        ts: i64 = 0,
        heap_size: i64 = 0,
        heap_native_size: i64 = 0,
        obj_count: i64 = 0,
        reachable_heap_size: i64 = 0,
        reachable_heap_native_size: i64 = 0,
        reachable_obj_count: i64 = 0,
        anon_rss_and_swap_size: i64 = 0,
        roots: ?[]const ?JavaHeapStats.HeapRoots = null,
        oom_score_adj: i64 = 0,
        process_uptime_ms: i64 = 0,
        pub fn calcProtobufSize(self: *const JavaHeapStats.Sample) usize {
            var res: usize = 0;
            if (self.ts != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.TS_WIRE) + gremlin.sizes.sizeI64(self.ts);
            }
            if (self.heap_size != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.HEAP_SIZE_WIRE) + gremlin.sizes.sizeI64(self.heap_size);
            }
            if (self.heap_native_size != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.HEAP_NATIVE_SIZE_WIRE) + gremlin.sizes.sizeI64(self.heap_native_size);
            }
            if (self.obj_count != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.OBJ_COUNT_WIRE) + gremlin.sizes.sizeI64(self.obj_count);
            }
            if (self.reachable_heap_size != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.REACHABLE_HEAP_SIZE_WIRE) + gremlin.sizes.sizeI64(self.reachable_heap_size);
            }
            if (self.reachable_heap_native_size != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.REACHABLE_HEAP_NATIVE_SIZE_WIRE) + gremlin.sizes.sizeI64(self.reachable_heap_native_size);
            }
            if (self.reachable_obj_count != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.REACHABLE_OBJ_COUNT_WIRE) + gremlin.sizes.sizeI64(self.reachable_obj_count);
            }
            if (self.anon_rss_and_swap_size != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.ANON_RSS_AND_SWAP_SIZE_WIRE) + gremlin.sizes.sizeI64(self.anon_rss_and_swap_size);
            }
            if (self.roots) |arr| {
                for (arr) |maybe_v| {
                    res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.ROOTS_WIRE);
                    if (maybe_v) |v| {
                        const size = v.calcProtobufSize();
                        res += gremlin.sizes.sizeUsize(size) + size;
                    } else {
                        res += gremlin.sizes.sizeUsize(0);
                    }
                }
            }
            if (self.oom_score_adj != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.OOM_SCORE_ADJ_WIRE) + gremlin.sizes.sizeI64(self.oom_score_adj);
            }
            if (self.process_uptime_ms != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.SampleWire.PROCESS_UPTIME_MS_WIRE) + gremlin.sizes.sizeI64(self.process_uptime_ms);
            }
            return res;
        }
        pub fn encode(self: *const JavaHeapStats.Sample, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
            const size = self.calcProtobufSize();
            if (size == 0) {
                return &[_]u8{};
            }
            const buf = try allocator.alloc(u8, self.calcProtobufSize());
            var writer = gremlin.Writer.init(buf);
            self.encodeTo(&writer);
            return buf;
        }
        pub fn encodeTo(self: *const JavaHeapStats.Sample, target: *gremlin.Writer) void {
            if (self.ts != 0) {
                target.appendInt64(JavaHeapStats.SampleWire.TS_WIRE, self.ts);
            }
            if (self.heap_size != 0) {
                target.appendInt64(JavaHeapStats.SampleWire.HEAP_SIZE_WIRE, self.heap_size);
            }
            if (self.heap_native_size != 0) {
                target.appendInt64(JavaHeapStats.SampleWire.HEAP_NATIVE_SIZE_WIRE, self.heap_native_size);
            }
            if (self.obj_count != 0) {
                target.appendInt64(JavaHeapStats.SampleWire.OBJ_COUNT_WIRE, self.obj_count);
            }
            if (self.reachable_heap_size != 0) {
                target.appendInt64(JavaHeapStats.SampleWire.REACHABLE_HEAP_SIZE_WIRE, self.reachable_heap_size);
            }
            if (self.reachable_heap_native_size != 0) {
                target.appendInt64(JavaHeapStats.SampleWire.REACHABLE_HEAP_NATIVE_SIZE_WIRE, self.reachable_heap_native_size);
            }
            if (self.reachable_obj_count != 0) {
                target.appendInt64(JavaHeapStats.SampleWire.REACHABLE_OBJ_COUNT_WIRE, self.reachable_obj_count);
            }
            if (self.anon_rss_and_swap_size != 0) {
                target.appendInt64(JavaHeapStats.SampleWire.ANON_RSS_AND_SWAP_SIZE_WIRE, self.anon_rss_and_swap_size);
            }
            if (self.roots) |arr| {
                for (arr) |maybe_v| {
                    if (maybe_v) |v| {
                        const size = v.calcProtobufSize();
                        target.appendBytesTag(JavaHeapStats.SampleWire.ROOTS_WIRE, size);
                        v.encodeTo(target);
                    } else {
                        target.appendBytesTag(JavaHeapStats.SampleWire.ROOTS_WIRE, 0);
                    }
                }
            }
            if (self.oom_score_adj != 0) {
                target.appendInt64(JavaHeapStats.SampleWire.OOM_SCORE_ADJ_WIRE, self.oom_score_adj);
            }
            if (self.process_uptime_ms != 0) {
                target.appendInt64(JavaHeapStats.SampleWire.PROCESS_UPTIME_MS_WIRE, self.process_uptime_ms);
            }
        }
    };
    pub const SampleReader = struct {
        buf: gremlin.Reader,
        _ts: i64 = 0,
        _heap_size: i64 = 0,
        _heap_native_size: i64 = 0,
        _obj_count: i64 = 0,
        _reachable_heap_size: i64 = 0,
        _reachable_heap_native_size: i64 = 0,
        _reachable_obj_count: i64 = 0,
        _anon_rss_and_swap_size: i64 = 0,
        _roots_offset: ?usize = null,
        _roots_last_offset: ?usize = null,
        _roots_cnt: usize = 0,
        _oom_score_adj: i64 = 0,
        _process_uptime_ms: i64 = 0,
        pub fn init(src: []const u8) gremlin.Error!JavaHeapStats.SampleReader {
            const buf = gremlin.Reader.init(src);
            var res = JavaHeapStats.SampleReader{ .buf = buf };
            if (buf.buf.len == 0) {
                return res;
            }
            var offset: usize = 0;
            while (buf.hasNext(offset, 0)) {
                const tag = try buf.readTagAt(offset);
                offset += tag.size;
                switch (tag.number) {
                    JavaHeapStats.SampleWire.TS_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._ts = result.value;
                    },
                    JavaHeapStats.SampleWire.HEAP_SIZE_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._heap_size = result.value;
                    },
                    JavaHeapStats.SampleWire.HEAP_NATIVE_SIZE_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._heap_native_size = result.value;
                    },
                    JavaHeapStats.SampleWire.OBJ_COUNT_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._obj_count = result.value;
                    },
                    JavaHeapStats.SampleWire.REACHABLE_HEAP_SIZE_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._reachable_heap_size = result.value;
                    },
                    JavaHeapStats.SampleWire.REACHABLE_HEAP_NATIVE_SIZE_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._reachable_heap_native_size = result.value;
                    },
                    JavaHeapStats.SampleWire.REACHABLE_OBJ_COUNT_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._reachable_obj_count = result.value;
                    },
                    JavaHeapStats.SampleWire.ANON_RSS_AND_SWAP_SIZE_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._anon_rss_and_swap_size = result.value;
                    },
                    JavaHeapStats.SampleWire.ROOTS_WIRE => {
                        const result = try buf.readBytes(offset);
                        offset += result.size;
                        if (res._roots_offset == null) {
                            res._roots_offset = offset - result.size;
                        }
                        res._roots_last_offset = offset;
                        res._roots_cnt += 1;
                    },
                    JavaHeapStats.SampleWire.OOM_SCORE_ADJ_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._oom_score_adj = result.value;
                    },
                    JavaHeapStats.SampleWire.PROCESS_UPTIME_MS_WIRE => {
                        const result = try buf.readInt64(offset);
                        offset += result.size;
                        res._process_uptime_ms = result.value;
                    },
                    else => {
                        offset = try buf.skipData(offset, tag.wire);
                    },
                }
            }
            return res;
        }
        pub fn sourceBytes(self: *const @This()) []const u8 {
            return self.buf.buf;
        }
        pub inline fn getTs(self: *const JavaHeapStats.SampleReader) i64 {
            return self._ts;
        }
        pub inline fn getHeapSize(self: *const JavaHeapStats.SampleReader) i64 {
            return self._heap_size;
        }
        pub inline fn getHeapNativeSize(self: *const JavaHeapStats.SampleReader) i64 {
            return self._heap_native_size;
        }
        pub inline fn getObjCount(self: *const JavaHeapStats.SampleReader) i64 {
            return self._obj_count;
        }
        pub inline fn getReachableHeapSize(self: *const JavaHeapStats.SampleReader) i64 {
            return self._reachable_heap_size;
        }
        pub inline fn getReachableHeapNativeSize(self: *const JavaHeapStats.SampleReader) i64 {
            return self._reachable_heap_native_size;
        }
        pub inline fn getReachableObjCount(self: *const JavaHeapStats.SampleReader) i64 {
            return self._reachable_obj_count;
        }
        pub inline fn getAnonRssAndSwapSize(self: *const JavaHeapStats.SampleReader) i64 {
            return self._anon_rss_and_swap_size;
        }
        pub fn rootsCount(self: *const JavaHeapStats.SampleReader) usize {
            return self._roots_cnt;
        }
        pub fn rootsNext(self: *JavaHeapStats.SampleReader) ?JavaHeapStats.HeapRootsReader {
            if (self._roots_offset == null) return null;
            const current_offset = self._roots_offset.?;
            const result = self.buf.readBytes(current_offset) catch return null;
            const msg = JavaHeapStats.HeapRootsReader.init(result.value) catch return null;
            if (self._roots_last_offset != null and current_offset >= self._roots_last_offset.?) {
                self._roots_offset = null;
                return msg;
            }
            if (self._roots_last_offset == null) unreachable;
            var next_offset = current_offset + result.size;
            const max_offset = self._roots_last_offset.?;
            while (next_offset <= max_offset and self.buf.hasNext(next_offset, 0)) {
                const tag = self.buf.readTagAt(next_offset) catch break;
                next_offset += tag.size;
                if (tag.number == JavaHeapStats.SampleWire.ROOTS_WIRE) {
                    self._roots_offset = next_offset;
                    return msg;
                } else {
                    next_offset = self.buf.skipData(next_offset, tag.wire) catch break;
                }
            }
            self._roots_offset = null;
            return msg;
        }
        pub inline fn getOomScoreAdj(self: *const JavaHeapStats.SampleReader) i64 {
            return self._oom_score_adj;
        }
        pub inline fn getProcessUptimeMs(self: *const JavaHeapStats.SampleReader) i64 {
            return self._process_uptime_ms;
        }
    };
    const InstanceStatsWire = struct {
        const UPID_WIRE: gremlin.ProtoWireNumber = 1;
        const PROCESS_WIRE: gremlin.ProtoWireNumber = 2;
        const SAMPLES_WIRE: gremlin.ProtoWireNumber = 3;
    };
    pub const InstanceStats = struct {
        // fields
        upid: u32 = 0,
        process: ?process_metadata.AndroidProcessMetadata = null,
        samples: ?[]const ?JavaHeapStats.Sample = null,
        pub fn calcProtobufSize(self: *const JavaHeapStats.InstanceStats) usize {
            var res: usize = 0;
            if (self.upid != 0) {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStats.InstanceStatsWire.UPID_WIRE) + gremlin.sizes.sizeU32(self.upid);
            }
            if (self.process) |v| {
                const size = v.calcProtobufSize();
                if (size > 0) {
                    res += gremlin.sizes.sizeWireNumber(JavaHeapStats.InstanceStatsWire.PROCESS_WIRE) + gremlin.sizes.sizeUsize(size) + size;
                }
            }
            if (self.samples) |arr| {
                for (arr) |maybe_v| {
                    res += gremlin.sizes.sizeWireNumber(JavaHeapStats.InstanceStatsWire.SAMPLES_WIRE);
                    if (maybe_v) |v| {
                        const size = v.calcProtobufSize();
                        res += gremlin.sizes.sizeUsize(size) + size;
                    } else {
                        res += gremlin.sizes.sizeUsize(0);
                    }
                }
            }
            return res;
        }
        pub fn encode(self: *const JavaHeapStats.InstanceStats, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
            const size = self.calcProtobufSize();
            if (size == 0) {
                return &[_]u8{};
            }
            const buf = try allocator.alloc(u8, self.calcProtobufSize());
            var writer = gremlin.Writer.init(buf);
            self.encodeTo(&writer);
            return buf;
        }
        pub fn encodeTo(self: *const JavaHeapStats.InstanceStats, target: *gremlin.Writer) void {
            if (self.upid != 0) {
                target.appendUint32(JavaHeapStats.InstanceStatsWire.UPID_WIRE, self.upid);
            }
            if (self.process) |v| {
                const size = v.calcProtobufSize();
                if (size > 0) {
                    target.appendBytesTag(JavaHeapStats.InstanceStatsWire.PROCESS_WIRE, size);
                    v.encodeTo(target);
                }
            }
            if (self.samples) |arr| {
                for (arr) |maybe_v| {
                    if (maybe_v) |v| {
                        const size = v.calcProtobufSize();
                        target.appendBytesTag(JavaHeapStats.InstanceStatsWire.SAMPLES_WIRE, size);
                        v.encodeTo(target);
                    } else {
                        target.appendBytesTag(JavaHeapStats.InstanceStatsWire.SAMPLES_WIRE, 0);
                    }
                }
            }
        }
    };
    pub const InstanceStatsReader = struct {
        buf: gremlin.Reader,
        _upid: u32 = 0,
        _process_buf: ?[]const u8 = null,
        _samples_offset: ?usize = null,
        _samples_last_offset: ?usize = null,
        _samples_cnt: usize = 0,
        pub fn init(src: []const u8) gremlin.Error!JavaHeapStats.InstanceStatsReader {
            const buf = gremlin.Reader.init(src);
            var res = JavaHeapStats.InstanceStatsReader{ .buf = buf };
            if (buf.buf.len == 0) {
                return res;
            }
            var offset: usize = 0;
            while (buf.hasNext(offset, 0)) {
                const tag = try buf.readTagAt(offset);
                offset += tag.size;
                switch (tag.number) {
                    JavaHeapStats.InstanceStatsWire.UPID_WIRE => {
                        const result = try buf.readUInt32(offset);
                        offset += result.size;
                        res._upid = result.value;
                    },
                    JavaHeapStats.InstanceStatsWire.PROCESS_WIRE => {
                        const result = try buf.readBytes(offset);
                        offset += result.size;
                        res._process_buf = result.value;
                    },
                    JavaHeapStats.InstanceStatsWire.SAMPLES_WIRE => {
                        const result = try buf.readBytes(offset);
                        offset += result.size;
                        if (res._samples_offset == null) {
                            res._samples_offset = offset - result.size;
                        }
                        res._samples_last_offset = offset;
                        res._samples_cnt += 1;
                    },
                    else => {
                        offset = try buf.skipData(offset, tag.wire);
                    },
                }
            }
            return res;
        }
        pub fn sourceBytes(self: *const @This()) []const u8 {
            return self.buf.buf;
        }
        pub inline fn getUpid(self: *const JavaHeapStats.InstanceStatsReader) u32 {
            return self._upid;
        }
        pub fn getProcess(self: *const JavaHeapStats.InstanceStatsReader) gremlin.Error!process_metadata.AndroidProcessMetadataReader {
            if (self._process_buf) |buf| {
                return try process_metadata.AndroidProcessMetadataReader.init(buf);
            }
            return try process_metadata.AndroidProcessMetadataReader.init(&[_]u8{});
        }
        pub fn samplesCount(self: *const JavaHeapStats.InstanceStatsReader) usize {
            return self._samples_cnt;
        }
        pub fn samplesNext(self: *JavaHeapStats.InstanceStatsReader) ?JavaHeapStats.SampleReader {
            if (self._samples_offset == null) return null;
            const current_offset = self._samples_offset.?;
            const result = self.buf.readBytes(current_offset) catch return null;
            const msg = JavaHeapStats.SampleReader.init(result.value) catch return null;
            if (self._samples_last_offset != null and current_offset >= self._samples_last_offset.?) {
                self._samples_offset = null;
                return msg;
            }
            if (self._samples_last_offset == null) unreachable;
            var next_offset = current_offset + result.size;
            const max_offset = self._samples_last_offset.?;
            while (next_offset <= max_offset and self.buf.hasNext(next_offset, 0)) {
                const tag = self.buf.readTagAt(next_offset) catch break;
                next_offset += tag.size;
                if (tag.number == JavaHeapStats.InstanceStatsWire.SAMPLES_WIRE) {
                    self._samples_offset = next_offset;
                    return msg;
                } else {
                    next_offset = self.buf.skipData(next_offset, tag.wire) catch break;
                }
            }
            self._samples_offset = null;
            return msg;
        }
    };
    // fields
    instance_stats: ?[]const ?JavaHeapStats.InstanceStats = null,
    pub fn calcProtobufSize(self: *const JavaHeapStats) usize {
        var res: usize = 0;
        if (self.instance_stats) |arr| {
            for (arr) |maybe_v| {
                res += gremlin.sizes.sizeWireNumber(JavaHeapStatsWire.INSTANCE_STATS_WIRE);
                if (maybe_v) |v| {
                    const size = v.calcProtobufSize();
                    res += gremlin.sizes.sizeUsize(size) + size;
                } else {
                    res += gremlin.sizes.sizeUsize(0);
                }
            }
        }
        return res;
    }
    pub fn encode(self: *const JavaHeapStats, allocator: std.mem.Allocator) gremlin.Error![]const u8 {
        const size = self.calcProtobufSize();
        if (size == 0) {
            return &[_]u8{};
        }
        const buf = try allocator.alloc(u8, self.calcProtobufSize());
        var writer = gremlin.Writer.init(buf);
        self.encodeTo(&writer);
        return buf;
    }
    pub fn encodeTo(self: *const JavaHeapStats, target: *gremlin.Writer) void {
        if (self.instance_stats) |arr| {
            for (arr) |maybe_v| {
                if (maybe_v) |v| {
                    const size = v.calcProtobufSize();
                    target.appendBytesTag(JavaHeapStatsWire.INSTANCE_STATS_WIRE, size);
                    v.encodeTo(target);
                } else {
                    target.appendBytesTag(JavaHeapStatsWire.INSTANCE_STATS_WIRE, 0);
                }
            }
        }
    }
};
pub const JavaHeapStatsReader = struct {
    buf: gremlin.Reader,
    _instance_stats_offset: ?usize = null,
    _instance_stats_last_offset: ?usize = null,
    _instance_stats_cnt: usize = 0,
    pub fn init(src: []const u8) gremlin.Error!JavaHeapStatsReader {
        const buf = gremlin.Reader.init(src);
        var res = JavaHeapStatsReader{ .buf = buf };
        if (buf.buf.len == 0) {
            return res;
        }
        var offset: usize = 0;
        while (buf.hasNext(offset, 0)) {
            const tag = try buf.readTagAt(offset);
            offset += tag.size;
            switch (tag.number) {
                JavaHeapStatsWire.INSTANCE_STATS_WIRE => {
                    const result = try buf.readBytes(offset);
                    offset += result.size;
                    if (res._instance_stats_offset == null) {
                        res._instance_stats_offset = offset - result.size;
                    }
                    res._instance_stats_last_offset = offset;
                    res._instance_stats_cnt += 1;
                },
                else => {
                    offset = try buf.skipData(offset, tag.wire);
                },
            }
        }
        return res;
    }
    pub fn sourceBytes(self: *const @This()) []const u8 {
        return self.buf.buf;
    }
    pub fn instanceStatsCount(self: *const JavaHeapStatsReader) usize {
        return self._instance_stats_cnt;
    }
    pub fn instanceStatsNext(self: *JavaHeapStatsReader) ?JavaHeapStats.InstanceStatsReader {
        if (self._instance_stats_offset == null) return null;
        const current_offset = self._instance_stats_offset.?;
        const result = self.buf.readBytes(current_offset) catch return null;
        const msg = JavaHeapStats.InstanceStatsReader.init(result.value) catch return null;
        if (self._instance_stats_last_offset != null and current_offset >= self._instance_stats_last_offset.?) {
            self._instance_stats_offset = null;
            return msg;
        }
        if (self._instance_stats_last_offset == null) unreachable;
        var next_offset = current_offset + result.size;
        const max_offset = self._instance_stats_last_offset.?;
        while (next_offset <= max_offset and self.buf.hasNext(next_offset, 0)) {
            const tag = self.buf.readTagAt(next_offset) catch break;
            next_offset += tag.size;
            if (tag.number == JavaHeapStatsWire.INSTANCE_STATS_WIRE) {
                self._instance_stats_offset = next_offset;
                return msg;
            } else {
                next_offset = self.buf.skipData(next_offset, tag.wire) catch break;
            }
        }
        self._instance_stats_offset = null;
        return msg;
    }
};
